<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>MIDAS@IIITD</title>
 <link href="https://midas.iiitd.edu.in/" rel="self"/>
 <link href="https://midas.iiitd.edu.in"/>
 <updated>2020-07-15T17:14:39+05:30</updated>
 <id>https://midas.iiitd.edu.in</id>
 <author>
   <name>Hitkul</name>
   <email>hitkuli@iiitd.ac.in</email>
 </author>

 
 <entry>
   <title>Somesh Kumar Singh</title>
   <link href="https://midas.iiitd.edu.in/team/Somesh-Kumar-Singh.html"/>
   <updated>2020-07-08T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Somesh-Kumar-Singh</id>
   <content type="html">&lt;p&gt;I am an under graduate at BITS Pilani, I am currently an intern at MIDAS, IIIT-D and working on adversarial machine learning. My work revolves around Natural Language Processing and Speech Processing, currently I am also exploring cognitive sciences.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sharad Chitlangia</title>
   <link href="https://midas.iiitd.edu.in/team/Sharad-Chitlangia.html"/>
   <updated>2020-07-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Sharad-Chitlangia</id>
   <content type="html">&lt;p&gt;Learning&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mehar Bhatia</title>
   <link href="https://midas.iiitd.edu.in/team/Mehar-Bhatia.html"/>
   <updated>2020-07-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Mehar-Bhatia</id>
   <content type="html">&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I am a full-time Research Assistant at MIDAS Lab, IIIT-Delhi under the guidance of Prof. Rajiv Ratn Shah. I hold a B.Tech degree (Batch of 2020) in Computer Science (minor in Mathematics) from Shiv Nadar University, Greater Noida. My research interest lies in NLP, Computational Linguistics and Speech Processing.&lt;/p&gt;

&lt;p&gt;To start a conversation, let’s talk about food and cities over a cup of coffee! :)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Arnav Wadhwa</title>
   <link href="https://midas.iiitd.edu.in/team/Arnav-Wadhwa.html"/>
   <updated>2020-07-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Arnav-Wadhwa</id>
   <content type="html">&lt;p&gt;“Can machines be as creative as us?” 
— A question I used to ponder upon while designing computer graphics, led me towards the field of artificial intelligence.&lt;/p&gt;

&lt;p&gt;Having worked for more than 2 years at labs of national importance (CSIR and ISRO); building projects for the Government of India’s AI Mission Phase-1; collaborating with tech-giants catering their product needs; I explored a fair deal of the development and deployment side of what AI has to offer — primarily within Computer Vision, Remote Sensing, and Deep Learning.&lt;/p&gt;

&lt;p&gt;I know they learn what you teach them. Mostly, they learn what you don’t teach them. It’s about asking the right questions to the right data.
But my question remains unanswered.
Finding the answer with MIDAS.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rajaswa Patil</title>
   <link href="https://midas.iiitd.edu.in/team/Rajaswa-Patil.html"/>
   <updated>2020-07-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Rajaswa-Patil</id>
   <content type="html">&lt;p&gt;I am a final year undergraduate student at BITS Pilani (Goa Campus), pursuing a major in Electrical &amp;amp; Electronics engineering. I spend most of my time dabbling in research related to computational models of language. My primary research areas of interest include Natural Language Processing, Machine Learning, Cognitive Neuroscience &amp;amp; Psycholinguistics. I also play around with competitive data science and am currently a Competitions Expert on Kaggle.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mohit Sharma</title>
   <link href="https://midas.iiitd.edu.in/team/Mohit-Sharma.html"/>
   <updated>2020-04-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Mohit-Sharma</id>
   <content type="html">&lt;p&gt;I work on Video understanding and methods to tackle label noise. Please visit my website for more: mohitsharma29.github.io.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ritwik Mishra</title>
   <link href="https://midas.iiitd.edu.in/team/Ritwik-Mishra.html"/>
   <updated>2020-02-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Ritwik-Mishra</id>
   <content type="html">&lt;p&gt;I am pursuing PhD under the guidance of Dr. Rajiv Ratn Shah and Proff. Ponnurangam Kumaraguru, at IIIT-D. My broad research area is Natural Language Processing, specifically Hindi language. I wish to attain a sustantial amount of knowledge in and out of domain of expertise. And with that knowledge I want to make this a world a better place.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Transfer Learning for Detecting Hateful Sentiments in Code Switched Language</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Transfer-Learning-for-Detecting-Hateful-Sentiments-in-Code-Switched-Language.html"/>
   <updated>2020-01-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Transfer-Learning-for-Detecting-Hateful-Sentiments-in-Code-Switched-Language</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;With the phenomenal increase in the penetration of social media in linguistically diverse demographic regions, conversations have become more casual and multilingual. The rise of informal code-switched multilingual languages makes it tough for automated systems to monitor instances of hate speech, which are further intelligently disguised through the use of spelling variations, code-mixing, homophones, homonyms, and the absence of sophisticated grammar rules. Machine transliteration can be employed for converting the code-switched text into a singular script but poses the challenge of the semantical breakdown of the text. To overcome this drawback, this chapter investigates the application of transfer learning. The CNN-based neural models are trained on a large dataset of hateful tweets in a chosen primary language, followed by retraining on the small transliterated dataset in the same language. Since transfer learning can act as an effective strategy to reuse already learned features in learning a specialized task through cross-domain knowledge transfer, hate speech classification on a large English corpus can act as source tasks to help in obtaining pre-trained deep learning classifiers for the target task of classifying tweets translated in English from other code-switched languages. Effects of the different types of popular word embeddings and multiple supervised inputs such as the LIWC, the presence of profanities, and sentiment are carefully studied to derive the most representative combination of input settings that can help achieve state-of-the-art hate speech detection from code-switched multilingual short texts on Twitter.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Multilingual Sentiment Analysis</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Multilingual-Sentiment-Analysis.html"/>
   <updated>2020-01-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Multilingual-Sentiment-Analysis</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Sentiment analysis has empowered researchers and analysts to extract opinions of people regarding various products, services, events and other entities. This has been made possible due to an astronomical rise in the amount of text data being made available on the Internet, not only in English but also in many regional languages around the world as well, along with the recent advancements in the field of machine learning and deep learning. It has been observed that deep learning models produce the state-of-the-art prediction results without the need for domain expertise or handcrafted feature engineering, unlike traditional machine learning-based algorithms. In this chapter, we wish to focus on sentiment analysis of various low resource languages having limited sentiment analysis resources such as annotated datasets, word embeddings and sentiment lexicons, along with English. Techniques to refine word embeddings for sentiment analysis and improve word embedding coverage in low resource languages are also covered. Finally, we discuss the major challenges involved in multilingual sentiment analysis and explain novel deep learning-based solutions to overcome them.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Deep Learning Approaches for Speech Emotion Recognition</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Deep-Learning-Approaches-for-Speech-Emotion-Recognition.html"/>
   <updated>2020-01-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Deep-Learning-Approaches-for-Speech-Emotion-Recognition</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In recent times, the rise of several multimodal (audio, video, etc.) content-sharing sites like Soundcloud and Dubsmash have made development of sentiment analytical techniques for these imperative. Particularly, there is much to explore when it comes to audio data, which has proliferated rapidly. Of all the various aspects of audio sentiment studies, emotion recognition in speech signals has gained momentum and attention in recent times. Recognizing specific emotions inherent in spoken language could go a long way in healthcare, information sciences, human–computer interaction, etc. This chapter examines the process of delineating sentiments from speech, and the impact of various deep learning techniques on the same. Factors like extracting relevant features and the performances of several deep learning architectures on such datasets are analyzed. Performances using various classical and deep learning approaches are presented as well. Finally, some conclusions and suggestions on the way forward are discussed.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Aspect Based Sentiment Analysis of Financial Headlines and Microblogs</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Aspect-Based-Sentiment-Analysis-of-Financial-Headlines-and-Microblogs.html"/>
   <updated>2020-01-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Aspect-Based-Sentiment-Analysis-of-Financial-Headlines-and-Microblogs</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;To improve the performance in e-commerce markets, big giants like Amazon, Myntra and Flipkart are providing consumers with a platform to review their services and also give them an opportunity to provide a useful insight of the service to the future buyers. On the other hand, companies use such reviews to make a significant upgradation in their products (or services) to survive in the competition from others in the market. This shows the importance of studying user views or opinions on a particular product (or service) consumed by users. In Natural Language Processing (NLP), the process of studying such user opinion is termed as opinion mining. It is a task of finding out overall sentiment present in a review. Past research in this area has assumed that a sentence cannot have multiple sentiments associated with it. However, this is not true. For example, “This car looks beautiful, but does not handle very well.” comprises a positive sentiment towards the looks of the car but a negative sentiment towards its handling. To address such issues, aspect-based sentiment analysis (ABSA) was introduced. ABSA aims to detect an aspect (i.e. features) in a given text and then perform sentiment analysis of the text with respect to that aspect. The chapter aims to discuss the concept of ABSA for the problem introduced as a FiQA 2018 challenge subtask 1 (https://sites.google.com/view/fiqa) in WWW 2018 shared task. It highlights all the state-of-the-art models in the domain and discusses some new approaches. We propose neural network models combined with hand-engineered features and attention mechanism, to perform ABSA on financial headlines and microblogs. Our proposed model outperformed the existing state-of-the-art results in sentiment part by 50% and in the aspect part by 20%.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Harnessing GANs for Zero-shot Learning of New Classes in Visual Speech Recognition.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Harnessing-GANs-for-Zero-shot-Learning-of-New-Classes-in-Visual-Speech-Recognition/html"/>
   <updated>2020-01-02T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Harnessing-GANs-for-Zero-shot-Learning-of-New-Classes-in-Visual-Speech-Recognition/Harnessing-GANs-for-Zero-shot-Learning-of-New-Classes-in-Visual-Speech-Recognition.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Visual Speech Recognition (VSR) is the process of recognizing or interpreting speech by watching the lip movements of the speaker. Recent machine learning based approaches model VSR as a classification problem; however, the scarcity of training data leads to error-prone systems with very low accuracies in predicting unseen classes. To solve this problem, we present a novel approach to zero-shot learning by generating new classes using Generative Adversarial Networks (GANs), and show how the addition of unseen class samples increases the accuracy of a VSR system by a significant margin of 27% and allows it to handle speaker-independent out-of-vocabulary phrases. We also show that our models are language agnostic and therefore capable of seamlessly generating, using English training data, videos for a new language (Hindi). To the best of our knowledge, this is the first work to show empirical evidence of the use of GANs for generating training samples
of unseen classes in the domain of VSR, hence facilitating zero-shot learning. We make the added videos for new classes publicly available along with our code&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo movement.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/MeTooMA-Multi-Aspect-Annotations-of-Tweets-Related-to-the-MeToo-movement/html"/>
   <updated>2019-12-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/MeTooMA-Multi-Aspect-Annotations-of-Tweets-Related-to-the-MeToo-movement/MeTooMA:-Multi-Aspect-Annotations-of-Tweets-Related-to-the-MeToo-movement.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper, we present a dataset containing 9,973 tweets related to the MeToo movement that were manually annotated for five different linguistic aspects: relevance, stance, hate speech, sarcasm, and dialogue acts. We present a detailed account of the data collection and annotation processes. The annotations have a very high inter-annotator agreement (0.79 to 0.93 k-alpha) due to the domain expertise of the annotators and clear annotation instructions. We analyze the data in terms of geographical distribution, label correlations, and keywords. Lastly, we present some potential use cases of this dataset. We expect this dataset would be of great interest to psycholinguists, socio-linguists, and computational linguists to study the discursive space of digitally mobilized social movements on sensitive issues like sexual harassment.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Leveraging BERT with Mix Up for Sentence Classification</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Leveraging-BERT-with-Mix-Up-for-Sentence-Classification.html"/>
   <updated>2019-11-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Leveraging-BERT-with-Mix-Up-for-Sentence-Classification</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;NA&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>An Iterative Approach for Identifying Complaint Based Tweets in Social Media Platforms</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/An-Iterative-Approach-for-Identifying-Complaint-Based-Tweets-in-Social-Media-Platforms.html"/>
   <updated>2019-11-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/An-Iterative-Approach-for-Identifying-Complaint-Based-Tweets-in-Social-Media-Platforms</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Twitter is a social media platform where users express opinions over a variety of issues. Posts offering grievances or complaints can be utilized by private/ public organizations to improve their service and promptly gauge a low-cost assessment. In this paper, we propose an iterative methodology which aims to identify complaint based posts pertaining to the transport domain. We perform comprehensive evaluations along with releasing a novel dataset for the research purposes.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Suicide Risk Assessment via Temporal Psycholinguistic Modeling</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Suicide-Risk-Assessment-via-Temporal-Psycholinguistic-Modeling.html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Suicide-Risk-Assessment-via-Temporal-Psycholinguistic-Modeling</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Social media platforms are increasingly being used for study-ing  psycho-linguistic  phenomenon  to  model  expressions  ofsuicidal intent in tweets. Most recent work in suicidal ideationdetection doesn’t leverage contextual psychological cues. Inthis work, we hypothesize that the contextual information em-bedded in the form of historical activities of users and ho-mophily  networks  formed  between  like-minded  individualsin Twitter can substantially improve existing techniques forautomated identification of suicidal tweets. This premise isextensively tested to yield state of the art results as comparedto linguistic only models, and the state-of-the-art model&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>SpotFake+: A Multimodal Framework for Fake News Detection via Transfer Learning</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/SpotFake+-A-Multimodal-Framework-for-Fake-News-Detection-via-Transfer-Learning.html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/SpotFake+:-A-Multimodal-Framework-for-Fake-News-Detection-via-Transfer-Learning</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Not available&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Keyphrase Generation for Scientific Articles using GANs</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Keyphrase-Generation-for-Scientific-Articles-using-GANs.html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Keyphrase-Generation-for-Scientific-Articles-using-GANs</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;n  this  paper,  we  present  a  keyphrase  generation  ap-proach  using  conditional  Generative  Adversarial  Net-works (GAN). In our GAN model, the generator outputsa sequence of keyphrases based on the title and abstractof a scientific article. The discriminator learns to distin-guish  between  machine-generated  and  human-curatedkeyphrases.  We  evaluate  this  approach  on  standardbenchmark  datasets.  Our  model  achieves  state-of-the-art performance in generation of abstractive keyphrasesand is also comparable to the best performing extractivetechniques. We also demonstrate that our method gener-ates more diverse keyphrases and make our implemen-tation publicly available&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Emotion Analysis on Social Media: Impact of Psychological and Contextual Cues</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Emotion-Analysis-on-Social-Media-Impact-of-Psychological-and-Contextual-Cues.html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Emotion-Analysis-on-Social-Media:-Impact-of-Psychological-and-Contextual-Cues</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The ubiquity of social media has led to a recent upsurge in the amount of expressive user-generated content, and leveraging this for a fine-grained analysis of the users’ emotions can pave the way for several other downstream tasks. Building on existing approaches for emotion spectrum analysis, we conduct a large-scale study of user emotions on Vent, the largest social media dataset with user-annotated textual posts from 63 distinct emotion categories. Our experiments establish the utility of linguistic homophily and psychological context using community-sensitive and temporal activity-based user-profiles for fine-grained emotion analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>ESAS: Towards Practical and Explainable Short Answer Scoring</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/ESAS-Towards-Practical-and-Explainable-Short-Answer-Scoring.html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/ESAS:-Towards-Practical-and-Explainable-Short-Answer-Scoring</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Motivated by the mandate to design and deploy a practical,real-world  educational  tool  for  grading,  we  extensively  ex-plore linguistic patterns for Short Answer Scoring (SAS) aswell as authorship feedback. We approach the SAS task viaa multipronged approach that employs linguistic context fea-tures for capturing domain-specific knowledge while empha-sizing on domain agnostic grading and detailed feedback viaan ensemble of explainable statistical models. Our method-ology quantitatively supersedes multiple automatic short an-swer scoring systems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Analysis of Parliamentary Debate Transcripts Using Community-Based Graphical Approaches.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Analysis-of-Parliamentary-Debate-Transcripts-Using-Community-Based-Graphical-Approaches/html"/>
   <updated>2019-10-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Analysis-of-Parliamentary-Debate-Transcripts-Using-Community-Based-Graphical-Approaches/Analysis-of-Parliamentary-Debate-Transcripts-Using-Community-Based-Graphical-Approaches.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;No available on the internet&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Video Summarization using Global Attention with Memory Network and LSTM</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Video-Summarization-using-Global-Attention-with-Memory-Network-and-LSTM.html"/>
   <updated>2019-10-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Video-Summarization-using-Global-Attention-with-Memory-Network-and-LSTM</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Videos are one of the most engaging and interesting mediums of effective information delivery and constitute the majority of the content generated online today. As human attention span shrinks, it is imperative to shorten videos while maintaining most of its information. The premier challenge is that summaries more intuitive to a human are difficult for machines to generalize. We present a simple approach to video summarization using Kernel Temporal Segmentation (KTS) for shot segmentation and a global attention based modified memory network module with LSTM for shot score learning. The modified memory network termed as Global Attention Memory Module (GAMM) increases the learning capability of the model and with the addition of LSTM, it is further able to learn better contextual features. Experiments on the benchmark datasets TVSum and SumMe show that our method outperforms the current state of the art by about 15%.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BigMM 2019 Best poster award</title>
   <link href="https://midas.iiitd.edu.in/news/shivangi-bigmm-poster.html"/>
   <updated>2019-09-16T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/shivangi-bigmm-poster</id>
   <content type="html">&lt;p&gt;Congratulations Shivangi Singhal on winning the best poster award at  IEEE BigMM19 for paper titled, “SPOTFAKE: A MULTI-MODAL FRAMEWORK FOR FAKE NEWS DETECTION”.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MobiVSR: Efficient and Light-weight Neural Network for Visual Speech Recognition on Mobile Devices.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/MobiVSR-Efficient-and-Light-weight-Neural-Network-for-Visual-Speech-Recognition-on-Mobile-Devices/html"/>
   <updated>2019-09-15T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/MobiVSR-Efficient-and-Light-weight-Neural-Network-for-Visual-Speech-Recognition-on-Mobile-Devices/MobiVSR:-Efficient-and-Light-weight-Neural-Network-for-Visual-Speech-Recognition-on-Mobile-Devices.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Visual speech recognition (VSR) is the task of recognizing spo-ken language from video input only, without any audio. VSRhas many applications as an assistive technology, especially ifit could be deployed in mobile devices and embedded systems.The need for intensive computational resources and large mem-ory footprint are two major obstacles in deploying neural net-work models for VSR in a resource constrained environment.We propose a novel end-to-end deep neural network architec-ture for word level VSR called MobiVSR with a design param-eter that aids in balancing the model’s accuracy and parametercount. We use depthwise 3D convolution along with channelshufﬂing for the ﬁrst time in the domain of VSR and show howit makes our model efﬁcient. MobiVSR achieves an accuracyof 70% on a challenging Lip Reading in the Wild dataset with6 times fewer parameters and 20 times smaller memory foot-print than the current state of the art. MobiVSR can also becompressed to 6 MB by applying post training quantization.Index Terms: video speech recognition,&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Multimodal Analysis of Disaster Tweets</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Multimodal-Analysis-of-Disaster-Tweets.html"/>
   <updated>2019-09-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Multimodal-Analysis-of-Disaster-Tweets</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Social media is inevitably the most abundant source
of actionable information in times of natural disasters. Most
of the data is either available in the form of text, images or
videos. Real-time analysis of such data during the events of
calamities poses many challenges to machine learning algorithms
that require a large amount of data to perform well. Multimodal
Twitter Dataset for Natural Disasters (CrisisMMD) is one such
novel dataset that provides annotated textual as well as image
data to researchers to aid the development of crisis response
mechanism which can leverage social media platforms to extract
useful information in times of crisis. In this paper, we analyze
multimodal data related to seven different natural calamities like
hurricanes, floods, earthquakes, etc. and propose a novel decision
diffusion technique to classify them into informative and noninformative categories. The proposed methodology outperforms
the text baselines by more than 4% accuracy and image baselines
by more than 3%&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Maybe look closer? Detecting Trolling Prone Images on Instagram.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Maybe-look-closer-Detecting-Trolling-Prone-Images-on-Instagram/html"/>
   <updated>2019-09-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Maybe-look-closer-Detecting-Trolling-Prone-Images-on-Instagram/Maybe-look-closer?-Detecting-Trolling-Prone-Images-on-Instagram.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Improvement in network infrastructure and smartphones have made images based social media platforms like Instagram and Flickr popular. The visual medium of communication has also led to an alarming increase in trolling incidents on social media. Though it is crucial to automatically detect trolling incidents on social media, in this paper, we look at the problem from the eye of prevention rather than detection. A system that can recognize trolling prone images can issue a warning to users before the content is posted online and prevent potential trolling incidents. We attempt to make a supervised classifier to detect trolling prone images and discuss why the conventional state-of-the-art image classification method does not work well for this task. We also provide an extensive analysis of trolling patterns in images from Instagram, discuss challenges and possible future paths in detail.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Automating Car Insurence Claims using Deep Learning Techniques.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Automating-Car-Insurence-Claims-using-Deep-Learning-Techniques/html"/>
   <updated>2019-09-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Automating-Car-Insurence-Claims-using-Deep-Learning-Techniques/Automating-Car-Insurence-Claims-using-Deep-Learning-Techniques.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;With the number of people driving a car increasing every day, there has been a proliferation in the number of cars insurance claims being registered. The life cycle of registering, processing and making a decision for each claim involves the manual examination by the service engineer who creates the damage report followed by the physical inspection by a surveyor from the insurance company which makes it a long drawn out process. We propose an end to end system to automate this process, which would be beneficial for both the company and the customer. This system takes images of the damaged car as input and gives relevant information like the damaged parts and provides an estimate of the extent of damage (no damage, mild or severe) to each part. This serves as a cue to then estimate the cost of repair which would be used in deciding insurance claim amount. We have experimented with popular instance segmentation models like the Mask R-CNN, PANet and an ensemble of these two along with a transfer learning [1] based VGG16 network to perform different tasks of localizing and detecting various classes of parts and damages found in the car. Additionally, the proposed system achieves good mAP scores for parts localization and damage localization (0.38 and 0.40 respectively).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Automatic Speech Recognition for Real-time Systems</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Automatic-Speech-Recognition-for-Real-time-Systems.html"/>
   <updated>2019-09-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Automatic-Speech-Recognition-for-Real-time-Systems</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Automatic Speech Recognition (ASR) systems have proven to be a useful tool to perform various day to day operations when used along with systems like Personal AI Assistants. Various industries require ASR to be trained in their domains. Music on Demand (MoD), over IVR, is one such industry where the user interacts with the dialogue system to play music using voice commands only. Domain adaptation of the model is expected to perform well on this domain as systems trained on public datasets are very generic in nature and not very domain-specific. To train the ASR for MoD, we experiment with the HMM-based classical approach and DeepSpeech2 on Voxforge dataset. We then fine-tune the DeepSpeech2 model on MoD data. With very limited data and little finetuning of the model, we were able to achieve 14.727% Word Error Rate (WER).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>ICDM/ICBK KGC Honourable Mention</title>
   <link href="https://midas.iiitd.edu.in/news/ICDM-Honourable-Mention.html"/>
   <updated>2019-08-31T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/ICDM Honourable Mention</id>
   <content type="html">&lt;p&gt;We are thrilled to announce that MIDAS team got the Honorable Mention Award of 2019 ICDM/ICBK KGC Contest. Congratulations to team Mehar Bhatia, Ritwik Mishra, Akash Gautam, Debanjan Mahata and Rajiv Ratn Shah.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Himanshu Singh</title>
   <link href="https://midas.iiitd.edu.in/team/Himanshu-SIngh.html"/>
   <updated>2019-08-26T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Himanshu-SIngh</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Yashvardhan Singh</title>
   <link href="https://midas.iiitd.edu.in/team/yashvardhan.html"/>
   <updated>2019-08-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/yashvardhan</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Prakhar Goel</title>
   <link href="https://midas.iiitd.edu.in/team/prakhar.html"/>
   <updated>2019-08-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/prakhar</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Nishtha Ahuja</title>
   <link href="https://midas.iiitd.edu.in/team/Nishtha-Ahuja.html"/>
   <updated>2019-08-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Nishtha-Ahuja</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>First prize in ACM INDIA Chapters Technology Solution Contest - 2019</title>
   <link href="https://midas.iiitd.edu.in/news/ACM-first.html"/>
   <updated>2019-08-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/ACM-first</id>
   <content type="html">&lt;p&gt;Our team won the first prize in ACM INDIA Chapters Technology Solution Contest - 2019. It was sponsored by ICERTIS. We were awarded Rs 65,000 for being the winner of this challenge. https://t.co/SvboGpKG8v?amp=1&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>TCS Fellowship Award to Shivangi Singhal</title>
   <link href="https://midas.iiitd.edu.in/news/shivangi-tcsfellow.html"/>
   <updated>2019-08-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/shivangi-tcsfellow</id>
   <content type="html">&lt;p&gt;Congratulations Shivangi Singhal on getting selected for the TCS PhD fellowship.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ashwat Kumar</title>
   <link href="https://midas.iiitd.edu.in/team/Ashwat-Kumar.html"/>
   <updated>2019-08-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Ashwat-Kumar</id>
   <content type="html">&lt;p&gt;I am a final year CSE undergraduate student at IIIT Delhi. My areas of interest include Deep Learning, Computer Vision and NLP. I am also ardent fan of F1 and Electronic Music.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Suhavi</title>
   <link href="https://midas.iiitd.edu.in/team/suhavi.html"/>
   <updated>2019-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/suhavi</id>
   <content type="html">&lt;p&gt;I am a final year, Computer Science Undergrad at IIIT-Delhi.
In the vast domain of the Machine Learning,more than the technology itself, it’s the problem statements that interest me.
At Midas, I am working on user-based depression detection model , based on a social media databases, hoping it leads to early help provision to those who need it.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Siddharth Dhawan</title>
   <link href="https://midas.iiitd.edu.in/team/siddharth-dhawan.html"/>
   <updated>2019-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/siddharth-dhawan</id>
   <content type="html">&lt;p&gt;I am a B.Tech Computer Science Undergraduate at IIIT Delhi, in my senior year. I am broadly interested in Machine Learning and Computer Vision. At MIDAS, I am working on the problem of suggesting citations for academic papers. My B.Tech Thesis is about Unsupervised Cross-Domain Adaptation of Person Re-identification, as a part of which I have been experimenting with Style Transfer, Conditional Image Generation and Disentangled Representations. I interned at Adobe Systems in the Summer of 2019, where I worked on the problem of assigning relevant names to scanned documents in the Adobe Scan App. I am also interested in Competitive Programming. I manage FooBar, the Comptetitive Programming Club at IIIT Delhi and I have been to multiple ICPC Asia Onsite Regional Contests during the years of my Undergraduate Eduaction.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pranay Raj Anand</title>
   <link href="https://midas.iiitd.edu.in/team/pranay-raj-anand.html"/>
   <updated>2019-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/pranay-raj-anand</id>
   <content type="html">&lt;p&gt;I am currently pursuing M.Tech in Computer Science &amp;amp; Engineering from IIIT-Delhi. My area of interest includes NLP, Computer Vision and 
Machine Learning. My on-going project at MIDAS Lab involves making typing possible with the head movement using computer vision and RNN models.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rajwinder Singh</title>
   <link href="https://midas.iiitd.edu.in/team/Rajwinder-Singh.html"/>
   <updated>2019-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Rajwinder-Singh</id>
   <content type="html">&lt;p&gt;I have joined MIDAS lab at IIIT Delhi as a Reaserch Assistant on 1st August 2019. Currently I am working on the project titled, “ASR systems and its Applications”, by primarily focusing on extraction
and analysis of emotions from human speech. Prior to joining MIDAS, I was a Research Intern at Design and Innovation Centre (DIC), UIET, Panjab University. My research interest lies in the broad area 
of application of AI for social good. I am interested to work on designing human-assistive machines or systems which are both emotionally and socially aware of its surroundings, which is essential for 
its effective interactions with humans and with other machines. I believe empowering systems with adaptive interaction ability can improve the quality of life in health and social care.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Anushka Bhandari</title>
   <link href="https://midas.iiitd.edu.in/team/Anushka-Bhandari.html"/>
   <updated>2019-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Anushka-Bhandari</id>
   <content type="html">&lt;p&gt;Anushka is a final year undergraduate researcher at Mélange and MIDAS Labs. She interned at Goldman Sachs in their core architecture team and bagged a PPO as well. Currently, she is researching on speech reconstruction problem for dysarthriac patients using Deep Learning Methods. An HCI enthusiast ,she has done her BTech Thesis on development and deployment of a system at a large scale. Her field of interests include Human Computer Interaction and Computer Vision for social good . Her recent work on LEAP: Scaffolding Collaborative Learning of Community Health Workers in India got accepted at CSCW’19, Austin Texas. 
She is the Creative Head of WiMLDS(Women In Machine Learning and Data Science), Delhi Chapter and volunteers her time to conduct workshops all over Delhi. She is also a volunteer at The Blind Relief Association, Delhi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Bagged support vector machines for emotion recognition from speech.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Bagged-Support-Vector-Machines-for-SER.html"/>
   <updated>2019-07-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Bagged Support Vector Machines for SER</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Speech emotion recognition, a highly promising and exciting problem in the field of Human Computer Interaction, has been studied and analyzed over several decades. It concerns the task of recognizing a speaker’s emotions from their speech recordings. Recognizing emotions from speech can go a long way in determining a person’s physical and psychological state of well-being. In this work we performed emotion classification on three corpora — the Berlin EmoDB, the Indian Institute of Technology Kharagpur Simulated Emotion Hindi Speech Corpus (IITKGP-SEHSC), and the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS). A combination of spectral features was extracted from them which was further processed and reduced to the required feature set. Ensemble learning has been proven to give superior performance compared to single estimators. We propose a bagged ensemble comprising of support vector machines with a Gaussian kernel as a viable algorithm for the problem at hand. We report the results obtained on the three datasets mentioned above.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper Accepted in KBS</title>
   <link href="https://midas.iiitd.edu.in/news/KBS-Acceptance.html"/>
   <updated>2019-07-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/KBS-Acceptance</id>
   <content type="html">&lt;p&gt;Our paper titled, “Bagged Support Vector Machines for Emotion Recognition from Speech” is got accepted to the Knowledge-Based Systems (KBS) journal with impact factor 4.529. Congrats authors, Anjali Bhavan; Pankaj Chauhan, Hitkul and Rajiv Ratn Shah.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SpotFake: A Multimodal Framework For Fake News Detection</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/spotfake.html"/>
   <updated>2019-07-21T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/spotfake</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;A  rapid  growth  in  the  amount  of  fake  news  onsocial  media  is  a  very  serious  concern  in  our  society.  It  isusually created by manipulating images, text, audio, and videos.This   indicates   that   there   is   a   need   of   multimodal   systemfor  fake  news  detection.  Though,  there  are  multimodal  fakenews  detection  systems  but  they  tend  to  solve  the  problemof  fake  news  by  considering  an  additional  sub-task  like  eventdiscriminator  and  finding  correlations  across  the  modalities.The  results  of  fake  news  detection  are  heavily  dependent  onthe subtask and in absence of subtask training, the performanceof  fake  news  detection  degrade  by  10%  on  an  average.To  solve  this  issue,  we  introduce  SpotFake-  a  multi-modalframework for fake news detection. Our proposed solution de-tects fake news without taking into account any other subtasks.It  exploits  both  the  textual  and  visual  features  of  an  article.Specifically,  we  made  use  of  language  models  (like  BERT)  tolearn text features, and image features are learned from VGG-19  pre-trained  on  ImageNet  dataset.  All  the  experiments  areperformed on two publicly available datasets,i.e.,Twitter andWeibo. The proposed model performs better than the currentstate-of-the-art  on  Twitter  and  Weibo  datasets  by  3.27%  and6.83%,  respectively.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Universal EEG Encoder for Learning Diverse Intelligent Tasks</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/UniversalEEGEncoderForLearningDiverseIntelligentTasks.html"/>
   <updated>2019-07-21T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/UniversalEEGEncoderForLearningDiverseIntelligentTasks</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Brain Computer Interfaces (BCI) have become very popular with Electroencephalography (EEG) being one of the most commonly used signal acquisition techniques. A major challenge in BCI studies is the individualistic analysis required for each task. Thus, task-specific feature extraction and classification are performed, which fails to generalize to other tasks with similar time-series EEG input data. To this end, we design a GRU-based universal deep encoding architecture to extract meaningful features from publicly available datasets for five diverse EEG-based classification tasks. Our network can generate task and format-independent data representation and outperform the state of the art EEGNet architecture on most experiments. We also compare our results with CNN-based, and Autoencoder networks, in turn performing local, spatial, temporal and unsupervised analysis on the data.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Facefetch: An Efficient and Scalable Face Retrieval System That uses Your Visual Memory</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Facefetch-An-Efficient-and-Scalable-Face-Retrieval-System-That-uses-Your-Visual-Memory.html"/>
   <updated>2019-07-20T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Facefetch:-An-Efficient-and-Scalable-Face-Retrieval-System-That-uses-Your-Visual-Memory</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Often in many situations in our life, we wish to envision the person we met but we could not recall what the person exactly look like except for a slight impression of the face. Yugo Sato et.al. introduced a face retrieval system for this problem, which utilises visual inputs from the users and attempts to retrieve the target face. The major drawback of their approach was that their system was slow and only applicable for small databases like Chicago Face Database. In this paper, we introduce a robust and scalable face retrieval system that is capable of retrieving the envisioned face from a large-scale database. Furthermore, instead of information specific to the target, our face retrieval system asks the user to select common face attributes that they remember their target face had, using which the system filters out the irrelevant faces thus speeding up the search process. Then our system asks the user to select several images that resemble with the envisioned face. On the basis of this selection, our system automatically reduces the “semantic gap” between human description and the computer based description of the target image. In order to evaluate our system, We conducted user studies on a large-scale database and established that our framework succeeded in beating the state of the art results in this particular task and thus proved itself to be very effective for retrieving the envisioned face image in approximately half the total number of search iterations and taking one-third of the overall search time thereby putting much less burden on the user.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Suril Mehta</title>
   <link href="https://midas.iiitd.edu.in/team/Suril-Mehta.html"/>
   <updated>2019-07-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Suril-Mehta</id>
   <content type="html">&lt;p&gt;Random Description.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>CISNet - Leveraging Community Interaction and Social Network Graphs For Detection Of Religious Hate Speech In Arabic</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/CISNet-Leveraging-Community-Interaction-and-Social-Network-Graphs-For-Detection-Of-Religious-Hate-Speech-In-Arabic.html"/>
   <updated>2019-07-02T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/CISNet---Leveraging-Community-Interaction-and-Social-Network-Graphs-For-Detection-Of-Religious-Hate-Speech-In-Arabic</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The rapid widespread of social media has led to some undesirable consequences like the
rapid increase of hateful content and offensive language. Religious Hate Speech, in particular, often leads to unrest and sometimes aggravates to violence against people on the basis of their religious affiliations. The richness of the Arabic morphology and the limited available resources makes this task especially challenging. The current state-of-the art approaches to detect hate speech in Arabic rely entirely on textual (lexical and semantic) cues. Our proposed methodology contends that leveraging Community-Interaction can better help us profile hate speech content on social media. Our proposed ARHNet (Arabic Religious Hate Speech Net) model incorporates both Arabic Word Embeddings and
Social Network Graphs for the detection of religious hate speech.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>ARHNet-Leveraging Community Interaction for Detection of Religious Hate Speech in Arabic</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/ARHney.html"/>
   <updated>2019-07-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/ARHney</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The rapid widespread of social media has lead to some undesirable consequences like the rapid increase of hateful content and offensive language. Religious Hate Speech, in particular, often leads to unrest and sometimes aggravates to violence against people on the basis of their religious affiliations. The richness of the Arabic morphology and the limited available resources makes this task especially challenging. The current state-of-the-art approaches to detect hate speech in Arabic rely entirely on textual (lexical and semantic) cues. Our proposed methodology contends that leveraging Community-Interaction can better help us profile hate speech content on social media. Our proposed ARHNet (Arabic Religious Hate Speech Net) model incorporates both Arabic Word Embeddings and Social Network Graphs for the detection of religious hate speech.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>#youtoo? Detection Of Personal Recollections Of Sexual Harassment On Social Media</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/YouToo-Detection-of-Personal-Recollections-of-Sexual-Harassment-on-Social-Media.html"/>
   <updated>2019-07-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/#YouToo?-Detection-of-Personal-Recollections-of-Sexual-Harassment-on-Social-Media</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The availability of large-scale online social data, coupled with computational methods can help us answer fundamental questions relat-ing to our social lives, particularly our health and well-being. The# MeToo trend has led to people talking about personal experiences of harassment more openly. This work at-tempts to aggregate such experiences of sex-ual abuse to facilitate a better understanding of social media constructs and to bring about social change. It has been found that disclo-sure of abuse has positive psychological im-pacts. Hence, we contend that such informa-tion can leveraged to create better campaigns for social change by analyzing how users react to these stories and to obtain a better insight into the consequences of sexual abuse. We use a three part Twitter-Specific Social Media Lan-guage Model to segregate personal recollec-tions of sexual harassment from Twitter posts. An extensive comparison with state-of-the-art generic and specific models along with a de-tailed error analysis explores the merit of our proposed model.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MIDAS at SemEval-2019 Task 9: Suggestion Mining from Online Reviews using ULMFiT.</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/MIDAS-at-SemEval-2019-Task-9-Suggestion-Mining-from-Online-Reviews-using-ULMFiT/html"/>
   <updated>2019-06-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/MIDAS-at-SemEval-2019-Task-9-Suggestion-Mining-from-Online-Reviews-using-ULMFiT/MIDAS-at-SemEval-2019-Task-9:-Suggestion-Mining-from-Online-Reviews-using-ULMFiT.</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper we present our approach and the system description for Sub Task A of SemEval 2019 Task 9: Suggestion Mining from Online Reviews and Forums. Given a sentence, the task asks to predict whether the sentence consists of a suggestion or not. Our model is based on Universal Language Model Finetuning for Text Classification. We apply various pre-processing techniques before training the language and the classification model. We further provide detailed analysis of the results obtained using the trained model. Our team ranked 10th out of 34 participants, achieving an F1 score of 0.7011. We publicly share our implementation
.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MIDAS at SemEval-2019 Task 6: Identifying Offensive Posts and Targeted Offense from Twitter</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/MIDAS-at-SemEval-2019-Task-6-Identifying-Offensive-Posts-and-Targeted-Offense-from-Twitter.html"/>
   <updated>2019-06-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/MIDAS-at-SemEval-2019-Task-6:-Identifying-Offensive-Posts-and-Targeted-Offense-from-Twitter</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;In this paper we present our approach and the system description for Sub Task A and Sub Task B of SemEval 2019 Task 6: Identifying and Categorizing Offensive Language in Social Media. Sub Task A involves identifying if a given tweet is offensive and Sub Task B involves detecting if an offensive tweet is targeted towards someone (group or an individual). Our models for Sub Task A is based on an ensemble of Convolutional Neural Network and Bidirectional LSTM, whereas for Sub Task B, we rely on a set of heuristics derived from the training data. We provide detailed analysis of the results obtained using the trained models. Our team ranked 5th out of 103 participants in Sub Task A, achieving a macro F1 score of 0.807, and ranked 8th out of 75 participants achieving a macro F1 of 0.695.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Avinash Swaminathan</title>
   <link href="https://midas.iiitd.edu.in/team/Avinash_Swaminathan.html"/>
   <updated>2019-06-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Avinash_Swaminathan</id>
   <content type="html">&lt;p&gt;I am third-year student at NSIT Delhi with research interests in NLP, Computer Vision, Adversarial Training. Currently working at MIDAS Labs under Dr.Rajiv Ratn Shah and collaborators from Bloomberg AI Dr.Debanajan Mahata and Mr.Raymond Zhang on developing GANs for keyphrase generation. To our knowledge, this is the first effort in the research community to apply GANs to problem of keyphrase generation. We are constantly developing new discriminator architectures and improving upon previous results, currently our GAN model has been able to beat state-of-the-art in predicting absent key phrases .&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Speak up, Fight Back! Detection of Social Media Disclosures of Sexual Harassment</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Speak-up,-Fight-Back!-Detection-of-Social-Media-Disclosures-of-Sexual-Harassment.html"/>
   <updated>2019-06-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Speak up, Fight Back! Detection of Social Media Disclosures of Sexual Harassment</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The# MeToo movement is an ongoing prevalent phenomenon on social media aiming to demonstrate the frequency and widespread of sexual harassment by providing a platform to speak narrate personal experiences of such harassment. The aggregation and analysis of such disclosures pave the way to development of technology-based prevention of sexual harassment. We contend that the lack of specificity in generic sentence classification models may not be the best way to tackle text subtleties that intrinsically prevail in a classification task as complex as identifying disclosures of sexual harassment. We propose the Disclosure Language Model, a three part ULMFiT architecture, consisting of a Language model, a Medium-Specific (Twitter) model and a Task-Specific classifier to tackle this problem and create a manually annotated real-world dataset to test our technique on this, to show that using a Discourse Language Model often yields better classification performance over (i) Generic deep learning based sentence classification models (ii) existing models that rely on handcrafted stylistic features. An extensive comparison with state-of-the-art generic and specific models along with a detailed error analysis presents the case for our proposed methodology.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>SNAP-BATNET: Cascading Author Profiling and Social Network Graphs for Suicide Ideation Detection on Social Media</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/SNAP-BATNET-Cascading-Author-Profiling-and-Social-Network-Graphs-for-Suicide-Ideation-Detection-on-Social-Media.html"/>
   <updated>2019-06-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/SNAP-BATNET: Cascading Author Profiling and Social Network Graphs for Suicide Ideation Detection on Social Media</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Suicide is a leading cause of death among youth and the use of social media to detect suicidal ideation is an active line of research. While it has been established that these users share a common set of properties, the current state-of-the-art approaches utilize only text-based (stylistic and semantic) cues. We contend that the use of information from networks in the form of condensed social graph embeddings and author profiling using features from historical data can be combined with an existing set of features to improve the performance. To that end, we experiment on a manually annotated dataset of tweets created using a three-phase strategy and propose SNAP-BATNET, a deep learning based model to extract text-based features and a novel Feature Stacking approach to combine other community-based information such as historical author profiling and graph embeddings that outperform the current state-of-the-art. We conduct a comprehensive quantitative analysis with baselines, both generic and specific, that presents the case for SNAP-BATNET, along with an error analysis that highlights the limitations and challenges faced paving the way to the future of AI-based suicide ideation detection.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Identifying Adverse Drug Reactions and Personal Health Experience Mentions from Twitter</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Identifying-Adverse-Drug-Reactions-and-Personal-Health-Experience-Mentions-from-Twitter.html"/>
   <updated>2019-05-25T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Identifying Adverse Drug Reactions and Personal Health Experience Mentions from Twitter</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Paper Abstract here.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Investigating Political Herd Mentality: A Community Sentiment Based Approach</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Investigating-Political-Herd-Mentality-A-Community-Sentiment-Based-Approach.html"/>
   <updated>2019-05-24T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Investigating Political Herd Mentality A Community Sentiment Based Approach</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Analyzing polarities and sentiments inherent in political speeches and debates poses an important problem today. This experiment aims to address this issue by analyzing publicly-available Hansard transcripts of the debates conducted in the UK Parliament. Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts, currently surpasses the benchmark results on the same dataset. Such sentiment classification systems could prove to be of great use in today’s politically turbulent times, for public knowledge of politicians’ stands on various relevant issues proves vital for good governance and citizenship. The experiments also demonstrate that continuous feature representations learned from graphs can improve performance on sentiment classification tasks significantly.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Abhishek Srivastava</title>
   <link href="https://midas.iiitd.edu.in/team/abhishek-srivastava.html"/>
   <updated>2019-05-20T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/abhishek-srivastava</id>
   <content type="html">&lt;p&gt;I am post graduate student at IIIT Delhi. Currently, I am working on melody generation from lyrics using conditional-lstm gans. My area of interest includes machine learning and natural language processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pakhi Bamdev</title>
   <link href="https://midas.iiitd.edu.in/team/pakhi.html"/>
   <updated>2019-05-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/pakhi</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Maitree leekha</title>
   <link href="https://midas.iiitd.edu.in/team/Maitree-Leekha.html"/>
   <updated>2019-03-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Maitree Leekha</id>
   <content type="html">&lt;h2 id=&quot;fields---cvscholargithubtwitterprofile_link-are-all-optionalalso-delete-this-line&quot;&gt;(Fields - CV,scholar,github,twitter,profile_link are all optional…Also delete this line)&lt;/h2&gt;
&lt;p&gt;layout: member
title: “Maitree Leekha”
position: Research Intern
type: Intern
organization: Delhi Technological University
email: maitreeleekha@yahoo.in
github: maitreeleekha
image: /assets/images/team/01-03-2019 Maitree Leekha.jpg
cv: /assets/pdfs/01-03-2019 Maitree Leekha Resume.pdf
—
The boundless possibility of trying out and the instant knowledge of the outcome that stimulates one for further analysis of a rationale in question is what I find most appealing about Computer Science. Keeping up an inquisitive and explorative attitude, I believe, leads to a constant learning process. This approach adds to the already immense potential for innovation that exists in this field.&lt;/p&gt;

&lt;p&gt;Hello there!
I am Maitree Leekha, a third year undergraduate student, pursuing B.Tech in Computer Science from Delhi Technological University, erstwhile Delhi College of Engineering; and since who so ever is reading this has probably already gone through my education and skills, I won’t talk much about that!&lt;/p&gt;

&lt;p&gt;In this era of technology, realizing how much our lives have been transformed by harnessing this powerful resource reinforces my unending urge to explore more!&lt;/p&gt;

&lt;p&gt;When I watch videos of Google adding some new element to their product or even when I log into Facebook every day and come up with some new feature, what I feel is a sense of marvel. Here are innovations that keep evolving not only technically but also hold infinite scope for creativity and logic. I feel a similar sense of exhilaration when I see my code run successfully. It is this feeling, which till date, drives me to not give up on even the toughest of problems.&lt;/p&gt;

&lt;p&gt;My period in this industry has just started, but even in this short span, I surely have strengthened my roots to some extent by means of my internships. I am of a firm belief that, driven by the fire of knowledge, what one can learn from herself, lays the strong foundation and forms the stepping stones for something extremely iconic. I am currently walking around with data science, machine learning and deep learning. These areas of artificial intelligence surprisingly seem to interest me, a front end person, quite a lot.&lt;/p&gt;

&lt;p&gt;I also love painting and capturing the world as I see it, into the pages of my art book.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mind Your Language</title>
   <link href="https://midas.iiitd.edu.in/blog/Mind-your-language.html"/>
   <updated>2019-01-29T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/blog/Mind-your-language</id>
   <content type="html">
&lt;p&gt;This blog is about our research project where we studied abuse and offense detection in the code switched pair of Hindi and English(i.e., Hinglish) under the expert guidance of Dr. Rajiv Ratn Shah, Dr. Roger Zimmermann, and Dr. Ponnurangam Kumaraguru.&lt;/p&gt;

&lt;p&gt;As we write this blog, we remember our journey as research interns at MIDAS Lab. We started this project as our college project in August ’18 when this idea was like a small seed which was sown by our friend Yaman Kumar who is experienced in this field. He introduced us with the highly intellectual professors at MIDAS Lab, who not only gave us a direction but also galvanized us each day into transforming this small idea into a full-fledged research project. As we started working, we became cognizant of the fact that it this a vital issue in today’s world and must be addressed. From what we discovered in our journey; we would like to give everyone a glimpse of it - A small idea that turned into a publication in one of the most prestigious conference of Artificial Intelligence - AAAI’19 at Honolulu, Hawaii, USA, as part of the student abstract and poster track.&lt;/p&gt;

&lt;h2 id=&quot;why-hinglishcode-switched-pair-of-hindi-and-english-&quot;&gt;Why Hinglish(code switched pair of Hindi and English) ?&lt;/h2&gt;
&lt;p&gt;In the Indian Subcontinent the number of Internet users has been continuously rising with the penetration of internet among the masses.It is being estimated that the number of internet users in India will cross 700 million by 2021.With about 53% of the users using Hinglish as the medium of communication on social media in India, the need of the the hour is to have some system to detect hate speech,offensive and abusive posts on social media.&lt;/p&gt;

&lt;h2 id=&quot;has-it-been-done-before&quot;&gt;Has it been done before?&lt;/h2&gt;
&lt;p&gt;Although there are many previous works which deal with Hindi and English hate speech (the top two languages in India), but very few on the code-switched version (Hinglish) of the two (Mathur et al. 2018). This is partially due to the following reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hinglish consists of no-fixed grammar and vocabulary. It derives a part of its semantics from Devnagari and another part from the Roman script.&lt;/li&gt;
  &lt;li&gt;Hinglish speech and written text consists of a concoction of words spoken in Hindi as well as English, but written in the Roman script. This makes the spellings variable and dependent on the writer of the text. 
Hence code-switched languages present tough challenges in terms of parsing and getting the meaning out of the text.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;our-contribution&quot;&gt;Our contribution!&lt;/h2&gt;

&lt;p&gt;Our work primarily consists of these steps: Preprocessing of the dataset, training of word embeddings,training of the classifier model and then using that on HEOT dataset. Preprocessing involves transliteration using Indic-transliteration python library and translation using Xlit-crowd conversion dictionary which was manually added with common Hinglish words and some profane words. This was followed by training of Glove(Pennington, Socher, and Manning 2014) and Twitter word2vec(Godin et al. 2015) embeddings on both the Davidson and HEOT dataset.Finally a ternary classification model was used using LSTM to classify these tweets into three categories(offensive, abusive and  benign).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog/myl-1.jpg&quot; width=&quot;800&quot; /&gt;
&lt;!-- ![alt text]() --&gt;&lt;/p&gt;

&lt;p&gt;As shown in the above figure the model was initially trained on the dataset provided by Davidson and then re-trained on the HEOT dataset so as to benefit from the transfer of learned features in the last stage.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog/myl-2.jpg&quot; width=&quot;800&quot; /&gt;
&lt;!-- ![alt text](/assets/images/blog/myl-2.jpg) --&gt;
We have produced “state of the art” results for english.Our model trained on Glove embeddings gives the best results on HEOT dataset. For comparison purposes we also calculate the results of our model on the Davidson dataset.&lt;/p&gt;

&lt;h2 id=&quot;applications&quot;&gt;Applications&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Detect False Propaganda by Political Groups in Elections.&lt;/li&gt;
  &lt;li&gt;Youtube/Netflix Subtitles – “Auto-beep” offensive language.&lt;/li&gt;
  &lt;li&gt;Online Social Media - Report Defamatory Pages and comments.&lt;/li&gt;
  &lt;li&gt;Feedback analytics for better user experience.&lt;/li&gt;
  &lt;li&gt;Real time “clean-chat” facility.&lt;/li&gt;
  &lt;li&gt;Censor board – Auto-eliminate abusive content&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;/h2&gt;

&lt;p&gt;In future we look to extend the work in the following ways:
Use dependency based word embeddings and compare them to the normal word embeddings.
Work on a model to classify images and videos(also having hindi text) into three categories offensive, abusive and  benign.
Detect and report facebook users and pages based on their recent posts.&lt;/p&gt;

&lt;p&gt;We feel immensely proud to be the part of this extremely enjoyable journey where we not only learnt just theoretically but also implemented those concepts to real life applications to witness the great impact that technology and artificial intelligence brings to life. We feel honoured and grateful on being able to contribute our skills and simultaneously learn each day from our guides and professors at MIDAS Lab who inspired us throughout the project. This has been a totally satisfying and rewarding experience and would wish to work with the team in future as well to use technology for a better tomorrow. Also, we would like to thank Puneet Mathur for sharing the HEOT dataset and inspiring us through his work in the following paper “Mathur, P.; Shah, R.; Sawhney, R.; and Mahata, D. 2018. Detecting offensive tweets in hindi-english code-switched language. In Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media, 18–26.”&lt;/p&gt;

&lt;p&gt;Above all, we thank Almighty God for giving us this opportunity, being with us and guiding us in all situations and making our way through each and every problem.&lt;/p&gt;

&lt;p&gt;Here is a link to a short video for better understanding of the project - &lt;a href=&quot;https://drive.google.com/open?id=1rpEcsv03B1yifjLftllK3Hep-Ecyzew2&quot;&gt;https://drive.google.com/open?id=1rpEcsv03B1yifjLftllK3Hep-Ecyzew2&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Vaibhav Varshney</title>
   <link href="https://midas.iiitd.edu.in/team/vaibhav-varshney.html"/>
   <updated>2019-01-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/vaibhav-varshney</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Gyanesh Anand</title>
   <link href="https://midas.iiitd.edu.in/team/Gyanesh-Anand.html"/>
   <updated>2019-01-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Gyanesh-Anand</id>
   <content type="html">&lt;p&gt;I am a B.Tech. Final year undergrad at IIIT Delhi. I work in the area of Machine Learning and Natural Language processing. In MIDAS, I am undertaking my B.Tech. Project which involves Constructing Knowledge Graphs in Medical Domain. I also work on Analysis of Online Social Media such as Twitter , reddit , instragram etc uncovering various insights from them. 
I love developing products with greater social impact. I believe strongly that a number of social issues can be solved by leveraging the power of technology. I am also the Coordinator of PRAYAAS , eco-social club of IIITD. 
I love painting a lot. I also enjoy photography and travelling.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Viresh Gupta</title>
   <link href="https://midas.iiitd.edu.in/team/viresh-gupta.html"/>
   <updated>2019-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/viresh-gupta</id>
   <content type="html">&lt;p&gt;I am a computer science student and love programming. I prefer working on impactful things, especially those that lie at the intersection of several domains. My broad research interests are multimodal research (extending over all domains - eeg, text, video, audio, discrete graphs), computer automation and work with modern AI tools like deep learning and machine learning. Other than research I love open source software, am a bookworm, skygazer, nature-lover and a gamer.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Palash Aggrawal</title>
   <link href="https://midas.iiitd.edu.in/team/palash-aggrawal.html"/>
   <updated>2019-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/palash-aggrawal</id>
   <content type="html">&lt;p&gt;Palash is a final year undergraduate researcher at SCAI, TavLab and MIDAS Labs. His field of interests include Deep Learning, Computer Vision and Natural Language Processing, and using these technologies for social good. His recent work on Universal EEG Encoder for learning diverse intelligent tasks got accepted as a publication in IEEE BigMM. Apart from research, he is highly enthusiastic about contributing to social causes and has been the lead organiser for the Summer Camp at IIIT Delhi held for the students of Government Schools in Delhi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Harsh Shrivastava</title>
   <link href="https://midas.iiitd.edu.in/team/Harsh-Shrivastava.html"/>
   <updated>2018-12-29T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Harsh-Shrivastava</id>
   <content type="html">&lt;p&gt;I’m a Bachelors in Engineering (Computer Science) third-year student working in the field of Deep Learning. I’m a result-oriented, highly motivated, focused and hardworking student who wants to work in Artificial Intelligence Research &amp;amp; Development.&lt;/p&gt;

&lt;p&gt;I see huge potential in Deep Learning in solving Medical Science Problems and I am quite interested and passionate about solving those problems. I have experience of over 7 months working as an Intern in Data Analysis, Data Science, Machine Learning and Deep Learning and have worked on some exciting projects. I’m continuously learning and improving my Research Calibre and Knowledge in the field to further take forward the research and development in this area.&lt;/p&gt;

&lt;p&gt;To know more about my work experience or just want to discuss your ideas with me, do email me at harsh.vardhan.shri@gmail.com.&lt;/p&gt;

&lt;p&gt;Thank you for visiting my profile.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shagun Uppal</title>
   <link href="https://midas.iiitd.edu.in/team/shagun-uppal.html"/>
   <updated>2018-12-18T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/shagun-uppal</id>
   <content type="html">&lt;p&gt;I am a third year undergraduate student at IIIT-Delhi. I am keenly interested in research areas of Machine Learning, Deep Learning, Computer Vision and NAtural Language Processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Abhishek Gupta</title>
   <link href="https://midas.iiitd.edu.in/team/abhishek-gupta.html"/>
   <updated>2018-12-18T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/abhishek-gupta</id>
   <content type="html">&lt;p&gt;I am an Undergraduate Researcher in the Computer Science Department at Indraprastha Institute of Information Technology, Delhi under the guidance of Prof. Rajiv Ratn Shah. I am interested in using deep learning for solving social issues and just doing some fun projects. I am a fan of books, anime and all things informative.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>V N S Rama Krishna Pinnimty</title>
   <link href="https://midas.iiitd.edu.in/team/V-N-S-Rama-Krishna-Pinnimty.html"/>
   <updated>2018-12-18T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/V-N-S-Rama-Krishna-Pinnimty</id>
   <content type="html">&lt;p&gt;I’m a CS undergrad at IIIT Bhubaneswar. My major areas of research include Machine Learning, Deep Learning, Computer Vision and Augmented Reality. I’m also passionate about developing Websites and Android Apps. I’ve interned at startups, MNC’s and research labs. Apart from this, I’m a District level (Hyderabad) basketball player and an absolute Anime buff.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Himani Sharma</title>
   <link href="https://midas.iiitd.edu.in/team/himani-sharma.html"/>
   <updated>2018-12-16T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/himani-sharma</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Prateek Rawat</title>
   <link href="https://midas.iiitd.edu.in/team/prateek.html"/>
   <updated>2018-12-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/prateek</id>
   <content type="html">&lt;p&gt;Pursuing Master’s in Computer Science in IIITD and working on Machine Learning and Natural Language Processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pallavi S. Rawat</title>
   <link href="https://midas.iiitd.edu.in/team/pallavi.html"/>
   <updated>2018-12-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/pallavi</id>
   <content type="html">&lt;p&gt;I am an enthusiatic learner and a positive person.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mehak Piplani</title>
   <link href="https://midas.iiitd.edu.in/team/mehak-piplani.html"/>
   <updated>2018-12-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/mehak-piplani</id>
   <content type="html">&lt;p&gt;I am a CS undergraduate studentat Indian Institute of Information Technology. My research intreset lies in data science and I love using achine learning for solving problems. Other than work I enjoy tarvelling.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hemant Yadav</title>
   <link href="https://midas.iiitd.edu.in/team/hemant-yadav.html"/>
   <updated>2018-12-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/hemant-yadav</id>
   <content type="html">&lt;p&gt;In the twenty-first century, the robot will take the place which slave labor occupied in ancient civilization - Nikola Tesla&lt;/p&gt;

&lt;p&gt;I am a Graduate Student from NSIT. Currently I am working as Research Assistant at IIIT-D on Automatic Speech Recognition project. Prevously I have worked on Computer vision, particularly on a key probelm related to Robotics Vision. My specialized area is Deep Learning.&lt;/p&gt;

&lt;p&gt;My long-term goal is to contribute to the Robotics community, particularly how Robots make intelligent decisions without any human intervention i.e. atrue Android, that’s the deciding factor if humans would be an interplanetary species or NO.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>IceBreaker: Solving Cold Start Problem for Video Recommendation Engines</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/IceBreaker-Solving-Cold-Start-Problem-for-Video-Recommendation-Engines.html"/>
   <updated>2018-12-12T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/IceBreaker:-Solving-Cold-Start-Problem-for-Video-Recommendation-Engines</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Internet has brought about a tremendous increase in content of all forms and, in that, video content constitutes the major backbone of the total content being published as well as watched. Thus it becomes imperative for video recommendation engines such as
Hulu to look for novel and innovative ways to recommend the newly added videos to their users. However, the problem with new videos is that they lack any sort of metadata and user interaction so as to be able to rate the videos for the consumers. To this effect, this
paper introduces the several techniques we develop for the Content Based Video Relevance Prediction (CBVRP) Challenge being hosted by Hulu for the ACM Multimedia Conference 2018. We employ different architectures on the CBVRP dataset to make use of the provided frame and video level features and generate predictions of videos that are similar to the other videos. We also implement several ensemble strategies to explore complementarity between both the types of provided features. The obtained results are encouraging and will impel the boundaries of research for multimedia based video recommendation systems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MyLipper: A Personalized System for Speech Reconstruction using Multi-view Visual Feeds</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/MyLipper-A-Personalized-System-for-Speech-Reconstruction-using-Multi-view-Visual-Feeds.html"/>
   <updated>2018-12-10T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/MyLipper:-A-Personalized-System-for-Speech-Reconstruction-using-Multi-view-Visual-Feeds</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Lipreading is the task of looking at, perceiving, and interpreting spoken symbols. It has a wide range of applications such as in surveillance, Internet telephony, speech reconstruction for silent movies and as an aid to a person with speech as well as hearing impairments. However, most of the work in lipreading literature has been limited to the classification of speech videos into text classes formed of phrases, words and sentences. Even this has been based on a highly constrained lexicon of words which, then subsequently translates to restriction on total number of classes (i.e, phrases, words and sentences) that are considered for the classification task. Recently, research has ventured into generating speech (audio) from silent video sequences. In spite of non-frontal views showing the potential of enhancing performance of speech reading and reconstruction systems, there have been no developments in using multiple camera feeds for the same. To this end, this paper presents a multi-view speech reading and reconstruction system. The major contribution of this paper is to present a model, namely MyLipper, which is a vocabulary and language agnostic and a real-time model that deals with a variety of poses of a speaker. The model leverages silent video feeds from multiple cameras recording a subject to generate intelligent speech for that speaker, thus being a personalized speech reconstruction model. It uses deep learning based STCNN+BiGRU architecture to achieve this goal. The results obtained using MyLipper show an improvement of over 20% in reconstructed speech’s intelligibility (as measured by PESQ) using multiple views as compared to a single view visual feed. This confirms the importance of exploiting multiple views in building an efficient speech reconstruction system. The paper further shows the optimal placement of cameras which would lead to the maximum intelligibility of speech. Further, we demonstrate the reconstructed audios overlaid on the corresponding videos obtained from MyLipper using a variety of videos from the dataset.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Multilingual Author Profiling from SMS</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Multilingual-Author-Profiling-from-SMS.html"/>
   <updated>2018-12-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Multilingual-Author-Profiling-from-SMS</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;This paper presents our solution for the Author Profiling task in the FIRE challenge 2018. This task mainly focuses on finding the age and gender of people from South Asian countries such as India, Pakistan, Nepal, and Bangladesh from their short messaging services (SMS). Since most of these people use a combination of languages such as Hindi, English and Roman Urdu (i.e., multilingual text) on social media platforms such as WhatsApp, Facebook, and Twitter, they also follow the same practice in SMS while communicating. Thus, we aim to perform author profiling by identifying gender and age of people by analyzing their multilingual SMS. In this paper, we classify the gender of a person into male or female categories. Moreover, we classify age into the following
three age groups: (i) 15-19, (ii) 20-24, and (iii) above 25. After preprocessing steps including tokenization and normalization, we provide the results of an experiment with several machine learning models like SVM, Random Forest, and Naive Bayes. Experimental results show that Naive Bayes provides competitive results when used with bilingual dictionary for translation and count vectorizer for feature extraction.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Harnessing AI for Kidney Glomeruli Classification</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/KidneyGlomeruli.html"/>
   <updated>2018-11-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/KidneyGlomeruli</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;A key challenge in renal diagnosis using digital pathology has been the scarcity of reliable annotated datasets that can act as a benchmark for histological investigations. This paper introduces a novel medical image dataset, titled Glomeruli Classification Database (GCDB), consisting of renal glomeruli images bifurcated into binary classes of normal and abnormal morphology. Based on this dataset, we direct our pioneering efforts to explore suitable deep neural network (DNN) techniques related to kidney tissue slide imaging so as to establish a state of the art in this relatively unexplored domain. The paper focuses on classifying normal and abnormal categories of glomeruli which are the vital blood filtration units of the kidney. The results obtained using publicly available transfer learning models are held in comparison with supervised classifiers configured with image features extracted from the last layers of pre-trained image classifiers. Contrary to popular belief, transfer learning models such as ResNet50 and InceptionV3 are empirically proved to under-perform for this particular task whereas the Logistic Regression model augmented with features from the InceptionResNetV2 show the most promising results on the GCDB dataset.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Did you offend me? Classification of Offensive Tweets in Hinglish Language</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Hinglish-offensive.html"/>
   <updated>2018-11-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Hinglish-offensive</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The use of code-switched languages (e.g., Hinglish, which is derived by the blending of Hindi with the English language) is getting much popular on Twitter due to their ease of  communication in native languages. However, spelling variations and absence of grammar rules introduce ambiguity and make it difficult to understand the text automatically. This paper presents the Multi-Input Multi-Channel Transfer Learning based model (MIMCT) to detect offensive (hate speech or abusive) Hinglish tweets from the proposed Hinglish Offensive Tweet (HOT) dataset using transfer learning coupled with multiple feature inputs. Specifically, it takes multiple primary word embedding along with secondary extracted features as inputs to train
a multi-channel CNN-LSTM architecture that has been pre-trained on English tweets through transfer learning. The proposed MIMCT model outperforms the baseline supervised 
classification models, transfer learning based CNN and LSTM models to establish itself as the state of the art in the unexplored domain of Hinglish offensive text classification.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Get IT Scored using AutoSAS - An Automated System for Scoring Short Answers</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/AutoSaS.html"/>
   <updated>2018-11-13T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/AutoSaS</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

</content>
 </entry>
 
 <entry>
   <title>Identification of Emergency Blood Donation Request on Twitter</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/BloodDonation.html"/>
   <updated>2018-11-12T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/BloodDonation</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Social media-based text mining in healthcare has received special attention in recent times due to the enhanced accessibility of social media sites like Twitter. The increasing trend of spreading important information in distress can help patients reach out to prospective blood donors in a time bound manner. However such manual efforts are mostly inefficient due to the limited network of a user. In a novel step to solve this problem, we present an annotated Emergency Blood Donation Request (EBDR) dataset to classify tweets referring to the necessity of urgent blood donation requirement. Additionally, we also present an automated feature-based SVM classification technique that can help selective EBDR tweets reach relevant personals as well as medical authorities. Our experiments also present a quantitative evidence that linguistic along with handcrafted heuristics can act as the most representative set of signals this task with an accuracy of 97.89%.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Exploring and Learning Suicidal Ideation Connotations in Social Media with DL</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Suicidial-ideation.html"/>
   <updated>2018-11-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Suicidial-ideation</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The increasing suicide rates amongst youth and its high correlation with suicidal ideation expression on social media warrants a deeper investigation into models for the detection of suicidal intent in text such as tweets to enable prevention. However, the complexity of the natural language constructs makes this task very challenging. Deep Learning architectures such as LSTMs, CNNs, and RNNs show promise in sentence level classification problems. This work investigates the ability of deep learning architectures to build an accurate and robust model for suicidal ideation de-
tection and compares their performance with standard baselines in text classification problems. The experimental results reveal the merit in C-LSTM based models as compared to other deep learning and machine learning based classification models for suicidal ideation detection.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Arijit Ghosh Chowdhury</title>
   <link href="https://midas.iiitd.edu.in/team/Arijit-Ghosh-Chowdhury.html"/>
   <updated>2018-11-10T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Arijit-Ghosh Chowdhury</id>
   <content type="html">&lt;p&gt;CS student interested in Natural Language Processing and Social Computing. Published papers to NAACL, ACL and ACM-HyperText. I am continuously trying to build complex solutions to problems pertaining to social issues. Also, I strongly believe that Veg Biryani is just Pulao.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Neural Machine Translation for English-Tamil</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/English2Tamil.html"/>
   <updated>2018-11-10T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/English2Tamil</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;A huge amount of valuable resources is avail- able on the web in English, which are of- ten translated into local languages to facilitate knowledge sharing among local people who are not much familiar with English. How- ever, translating such content manually is very tedious, costly, and time-consuming process. To this end, machine translation is an effi- cient approach to translate text without any hu- man involvement. Neural machine translation (NMT) is one of the most recent and effective translation technique amongst all existing ma- chine translation systems. In this paper, we apply NMT for English-Tamil language pair. We propose a novel neural machine translation technique using word-embedding along with Byte-Pair-Encoding (BPE) to develop an ef- ficient translation system that overcomes the OOV (Out Of Vocabulary) problem for lan- guages which do not have much translations available online. We use the BLEU score for evaluating the system performance. Ex- perimental results confirm that our proposed MIDAS translator (8.33 BLEU score) outper- forms Google translator (3.75 BLEU score).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mind Your Language: Abuse and Offense Detection for Code-Switched Languages</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Mind-Your-Language.html"/>
   <updated>2018-11-09T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Mind-Your-Language</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;In bilingual and multilingual societies like the Indian subcontinent, use of code-switched languages is much popular and convenient for the users. In this paper, we study offense and abuse detection in the code-switched pair of Hindi and English (i.e. Hinglish), the pair that is the most spoken. The task is made difficult due to non-fixed grammar, vocabulary, semantics and spellings of Hinglish language. We apply transfer learning and make a LSTM based model for hate speech classification. This model surpasses the performance shown by the current best models to establish itself as the state-of the-art in the unexplored domain of Hinglish offensive text classification.We also release our model and the embeddings trained for research purposes.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DeepLip: Speaker Independent Speech Synthesis using Multi-View Lipreading</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/DeepLip.html"/>
   <updated>2018-11-08T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/DeepLip</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

</content>
 </entry>
 
 <entry>
   <title>Lipper: Synthesizing Thy Speech using Multi-View Lipreading</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/lipper.html"/>
   <updated>2018-11-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/lipper</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

</content>
 </entry>
 
 <entry>
   <title>Exploring Classification of Histological Disease Bio-markers from Renal Biopsy Images</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Exploring-classification-from-renal-biopsy.html"/>
   <updated>2018-11-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Exploring-classification-from-renal-biopsy</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Identification of diseased kidney glomeruli and fibrotic regions, the two most significant biomarkers for chronic kidney diseases, remains subjective and time-consuming due to complete dependence on an expert kidney pathologist. In an attempt to automate the identification of tissue-level micro-structures from biopsy images, we investigate three deep learning techniques: traditional transfer learning, pre-trained deep neural networks for feature extraction followed by supervised classification and a novel Multi-Gaze Attention Network (MGANet) that uses multi-headed self-attention through parallel residual skip connections in a CNN architecture. We simultaneously introduce a Renal Glomeruli Fibrosis Histopathological (RGFH) database
pertaining to 935 glomeruli and 927 fibrosis images. As per our experimentation, transfer learning models such as ResNet50, InceptionResNetV2,VGG19 and InceptionV3 are
empirically proven to under-perform for classification of glomeruli into normal and abnormal morphology and classification of fibrosis patches into mild, moderate and severe categories. On the other hand, the Logistic Regression model augmented with features extracted from the InceptionResNetV2 shows promising results. Additionally, the experiments effectively ascertain that the proposed MGANet architecture outperforms both the baseline techniques to establish the state of the art accuracy of 87.25% and 81.47% for glomerluli and fibrosis classification respectively.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kush Misra</title>
   <link href="https://midas.iiitd.edu.in/team/Kush-Misra.html"/>
   <updated>2018-10-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Kush-Misra</id>
   <content type="html">&lt;p&gt;I am a final year undergraduate student at NSIT. I am passionate about learning new things and implementing ideas. My interests revolve around  machine learning, deep learning and data mining . I love playing basketball and I have represented Jammu district in regional level.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Puneet Mathur</title>
   <link href="https://midas.iiitd.edu.in/team/Puneet.html"/>
   <updated>2018-10-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Puneet</id>
   <content type="html">&lt;p&gt;Introduction: Experienced AI researcher with a penchant to advance technology to solve the mankind’s greatest challenges, I am a research assistant at MIDAS since January 2018. I have previously worked with Makemytrip and currently working at Estee Advisors as a algorithmic trader. I have published at prestigious venues like ACL, EMNLP, ISM, ICCSA and WACV. Reach out to me if you are interested in collaborating on deep learning projects in NLP, Multimedia retrieval, social media analysis, biomedical imaging, computer vision, bioinformatics and machine learning applications.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kiki Kills: Identifying Dangerous Challenge Videos from Social Media</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/KiKi-kills.html"/>
   <updated>2018-09-26T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/KiKi-kills</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;There has been upsurge in the number of people participating in challenges made popular through
social media channels. One of the examples of such a challenge is the Kiki
Challenge, in which people step out of their moving cars and
dance to the tunes of the song, “Kiki, Do you love me?”.
Such an action makes the people taking the challenge prone
to accidents and can also create nuisance for the others traveling on the road. In this work, we introduce the prevalence of such challenges in social media and show how the
machine learning community can aid in preventing dangerous situations triggered by them by developing models that
can distinguish between dangerous and non-dangerous chllenge videos. Towards this objective, we release a new dataset
namely MIDAS-KIKI dataset, consisting of manually annotated dangerous and non-dangerous Kiki challenge videos.
Further, we train a deep learning model to identify dangerous and non-dangerous videos, and report our results.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kiki Challenge Dataset Release</title>
   <link href="https://midas.iiitd.edu.in/blog/KiKI-challenge.html"/>
   <updated>2018-09-26T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/blog/KiKI-challenge</id>
   <content type="html">
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&quot;what-is-this-challenge-about&quot;&gt;What is this challenge about?&lt;/h3&gt;
&lt;p&gt;One of the most famous online social media challenge these days is the Kiki challenge. Also known as “In My Feelings Challenge” or “Do The Shiggy”, it originated when a comedian Shiggy released a video, dancing on the road to the tunes of this song by Drake. Since then people have considered it to be a challenge in which they need to get down of a moving car, and dance alongside the traffic risking their lives and getting their video captured.&lt;/p&gt;

&lt;h3 id=&quot;how-popular-is-the-challenge-&quot;&gt;How popular is the challenge ?&lt;/h3&gt;
&lt;p&gt;There is no country which has been left untouched when it comes to this. It originated in Canada and spread over the world including United States, Mexico, United Kingdom, India, South Africa, Costa Rica, Egypt, Argentina and so on. People are sharing thousands of tweets commonly involving their videos on a daily basis on social platforms like Twitter and Facebook.&lt;/p&gt;

&lt;h2 id=&quot;whats-wrong-&quot;&gt;What’s wrong !!?&lt;/h2&gt;
&lt;p&gt;While it is good to dance and burn some calories, but when it comes to the road it is not such a brilliant idea. There has been many reported incidents where people have been hit by speedy vehicles, fallen off the car and collided head-start with electric poles. It possesses a serious risk to life if not taken with precautions and may even lead to death.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/YuEbz_Qkx3Q?rel=0&amp;amp;autoplay=0
&amp;amp;start=15;end=22&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;our-contributions&quot;&gt;Our contributions&lt;/h2&gt;
&lt;p&gt;Realising the importance and implications that this challenge has on the life of so many people, MIDAS decided to build a system which can detect the danger in a given video. The exact methodology followed by us was -&lt;/p&gt;

&lt;h3 id=&quot;1-analysing-the-common-hashtags-used&quot;&gt;1. Analysing the common hashtags used&lt;/h3&gt;
&lt;p&gt;We started with collecting tweets for the last 15 days using the Tweepy API. Next, we scanned through the data to find out what were the top 20 most commonly used hashtags during the July-August duration using their frequency of occurrence.
Results of this analysis can be found here - &lt;a href=&quot;https://drive.google.com/file/d/1mCIu4Wk6xog8ATUOdIORmClCUgyT7sNt/view?usp=sharing&quot;&gt;Distribution of Hashtags in Twitter data&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-creating-a-dataset-from-social-platforms&quot;&gt;2. Creating a dataset from social platforms&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Tweet Collection: The common hashtags discovered in the previous step were used as keywords for further searching of tweets for the complete duration of late June to September. Data from hashtags such as #mumbai police and #egypt police which had comparatively smaller frequency were collected separately.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Video Collection: After we had a good set of tweets, we used the URLs provided as a parameter inside tweets to download corresponding videos.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Annotation: Two annotators worked through the complete list of videos categorising them as either safe or dangerous. Removal of retweeted videos as well as irrelevant videos which seemed to not relate was simultaneously done.
Cross annotation parameter was also calculated by labelling 400 videos for each of the annotators to ensure there was consistency. This test was successful and we obtained a high value (0.95) of Cohen’s Kappa.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-building-a-model-for-detecting-dangerous-incidents&quot;&gt;3. Building a model for detecting dangerous incidents&lt;/h3&gt;
&lt;p&gt;We built a video classification model with VGG16 as the base model. This was appended with a subtle combination of flatten, fully connected dense layers, max pooling layers and dropout layers.
The model works by taking as input a batch of data containing captured frames of the video we want to classify. The output produced is the probabilities of video between safe and dangerous. Thus we classify the category of the video after rounding the probabilities to the nearest possible values.
&lt;img src=&quot;https://drive.google.com/file/d/1-CAxz-_l6hG_AHbv3azHr9g5D2xdIfZz/view?usp=sharing&quot; alt=&quot;Structure of Model&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-evaluation-of-models-to-judge-their-consistency&quot;&gt;4. Evaluation of models to judge their consistency&lt;/h3&gt;
&lt;p&gt;We used model checkpointing to store the weights of the best model. Further, to determine the consistency of our model we evaluated it on the test set. An accuracy of 87 percent was obtained, along with a precision of 0.96, and recall score of 0.9.&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;/h2&gt;
&lt;p&gt;Although the current model is fair enough to generate good results, it can surely be improved to account for time analysis using recurrent neural network models. 
We also plan to create a hybrid model which can take into account both the textual and visual data in a tweet and generate results more accurately.&lt;/p&gt;

&lt;h3 id=&quot;the-following-video-provides-a-complete-summary&quot;&gt;The following video provides a complete summary:&lt;/h3&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1cU8REZhDGT3eEpz_txBRLxauRTKHdY15/preview&quot; width=&quot;640&quot; height=&quot;480&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;about-us&quot;&gt;About Us:&lt;/h2&gt;
&lt;h3 id=&quot;the-authors-involved-for-this-project-are&quot;&gt;The authors involved for this project are:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Nupur Baghel, Yaman Kumar, Paavini Nanda, Rajiv Ratn Shah, Debanjan Mahata and Roger Zimmermann&lt;/strong&gt; 
All of us are members of the MIDAS community.&lt;/p&gt;

&lt;p&gt;To help on improving research in this domain we are hereby releasing the dataset which contains more than 2.3k videos of the KIKI challenge collected from Twitter.&lt;/p&gt;
&lt;h2 id=&quot;kiki-datasets-download&quot;&gt;KIKI Datasets Download&lt;/h2&gt;
&lt;p&gt;For the time being the dataset is avalable on request. Anyone intrested can send us a request via E-mail stating there purpose of use (We did some work for you, just click &lt;a href=&quot;mailto: yamank.co@nsit.net.in?subject=Request For KiKi challenge dataset&quot;&gt;here&lt;/a&gt;). We will respond within 7 days.&lt;/p&gt;

&lt;p&gt;Please refre our dataset as below&lt;/p&gt;

&lt;p&gt;Nupur Baghel, Yaman Kumar, Paavini Nanda, Rajiv Ratn Shah, Debanjan Mahata and Roger Zimmermann : Kiki Kills: Identifying Dangerous Challenge Videos from Social Media (2018).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Astitwa Saxena</title>
   <link href="https://midas.iiitd.edu.in/team/Astitwa-Saxena.html"/>
   <updated>2018-09-19T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Astitwa-Saxena</id>
   <content type="html">&lt;p&gt;I am a CS undergraduate student at NSIT Delhi. I am interested in most places which require problem solving and logic in general. I have a strong interest in development which drives me to actively build new stuff. In my free time, I am a singer and you can catch my performances around Delhi!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Akash Gautam</title>
   <link href="https://midas.iiitd.edu.in/team/Akash-Gautam.html"/>
   <updated>2018-09-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Akash-Gautam</id>
   <content type="html">&lt;p&gt;I am a Computer Science student graduated from IIIT-Delhi, my work has been recognized in distinguished conferences like ICDM, IEEE BigMM. I am currently working towards deploying technologies for harnessing actionable insights from unstructured data. Feel free to reach out to me if you are interested in collaborating on topics like Natural Language Processing, Social Media Analysis, Ontology modeling, Knowledge graph construction, and user-generated content.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Nilay Shrivastava</title>
   <link href="https://midas.iiitd.edu.in/team/Nilay-Shrivastava.html"/>
   <updated>2018-09-08T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Nilay-Shrivastava</id>
   <content type="html">&lt;p&gt;I am a final year undergraduate student of Computer Engineering department at Netaji Subhas Institute of Technology. My interests spans across Mathematics (specifically Stochastic Calculus), Deep Learning, Gradient free Optimization algorithms and Quantum Computing/Information Processing. During my undergraduate degree I managed to squeeze internships at a startup Zeg.ai and then at Samsung Research, Banglore where I worked on constructing Deep Nets for low power devices. At NSIT I worked in Dr. Vijander Singh’s Control Engineering lab on Optimization problems. I am a KVPY and NTSE scholar too.&lt;/p&gt;

&lt;p&gt;Apart from mainstream academic work, I maintain a blog at&lt;img src=&quot;https://euler16.github.io&quot; alt=&quot;euler16.github.io&quot; /&gt;. I have also built a JavaScript library Qu.js (do &lt;img src=&quot;https://github.com/euler16/Qu.js&quot; alt=&quot;check it out&quot; /&gt;!).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Nupur Baghel</title>
   <link href="https://midas.iiitd.edu.in/team/nupur-baghel.html"/>
   <updated>2018-09-04T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/nupur-baghel</id>
   <content type="html">&lt;p&gt;I am a CS undergraduate student at NSIT Delhi. I like experimenting and trying out new things! I love machine learning, making mobile apps and working open source. I am also a big fan of classical dancing :D&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rajat Maheshwari</title>
   <link href="https://midas.iiitd.edu.in/team/Rajat-Maheshwari.html"/>
   <updated>2018-09-02T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Rajat-Maheshwari</id>
   <content type="html">&lt;p&gt;I believe that having a growth mindset and humility with a little bit of creativity and time management can help you achieve anything you desire. I realised that world will always be facing problems (sorry no utopia) and mostly digital in the coming future or problems that can be influenced and sorted by digital/technological means. At least for the next 5 years my primary goal is to gain skills to solve such problems and bring change in the world. Though there’s a big list of other things I want to achieve or experience in my life (If interested, send me a mail. I’ll forward it to you).&lt;/p&gt;

&lt;p&gt;Life is not short, You just gotta DO MORE.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shashwat Uttam</title>
   <link href="https://midas.iiitd.edu.in/team/Shashwat-Uttam.html"/>
   <updated>2018-09-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Shashwat-Uttam</id>
   <content type="html">&lt;p&gt;I am a Computer Science undergraduate student at NSIT. I’m interested in NLP and Computer Vision problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shashwat Aggarwal</title>
   <link href="https://midas.iiitd.edu.in/team/Shashwat-Aggarwal.html"/>
   <updated>2018-09-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Shashwat-Aggarwal</id>
   <content type="html">&lt;p&gt;Hi, I am Shashwat Aggarwal, a final year CS undergraduate student at NSIT Delhi. My research interests revolve around Natural Language Processing, Computer Vision and Deep Learning.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rajat Bansal</title>
   <link href="https://midas.iiitd.edu.in/team/rajat-bansal.html"/>
   <updated>2018-08-20T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/rajat-bansal</id>
   <content type="html">&lt;p&gt;Aspiring Data Scientist, an avid reader and a pro foodie. Likes to travel and meet exciting people. Somewhat of an introvert, so that’s it.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shivli Agrawal</title>
   <link href="https://midas.iiitd.edu.in/team/shivli-agrawal.html"/>
   <updated>2018-08-12T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/shivli-agrawal</id>
   <content type="html">&lt;p&gt;I am Shivli, currently a Software Engineer at Microsoft and a B.E. Computer Science graduate from NSIT, batch of 2018. I am into DL architectures for a while and would love to dive deeper. I have done some basic projects related to NLP and am enthusiastic about expanding my skill set and learning more. Happy to be here :).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Yukti Girdhar</title>
   <link href="https://midas.iiitd.edu.in/team/Yukit-girdhar.html"/>
   <updated>2018-08-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Yukit-girdhar</id>
   <content type="html">&lt;p&gt;I am Yukti, graduated from Computer Engineering NSIT in 2018. I am currently working as Software developer at Deutsche Bank, I am extremely interested in NLP and it’s applications in languages other than english so did my final year project on hindi story sentence classification.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mansi Agarwal</title>
   <link href="https://midas.iiitd.edu.in/team/mansi-agarwal.html"/>
   <updated>2018-08-09T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/mansi-agarwal</id>
   <content type="html">&lt;p&gt;There is a saying, which says, “The only thing permanent in life is change”. This perfectly holds true to the world of Computer Science where novel ideas are not a novelty. It is this novelty that entices me to this field and gives me a deep sense of professional pride.&lt;/p&gt;

&lt;p&gt;I am Mansi Agarwal,a Computer Science geek and a third year undergraduate student pursuing Computer Science and Engineering from Delhi Technological University(erstwhile Delhi College of Engineering).&lt;/p&gt;

&lt;p&gt;The concepts of Machine Learning and Artificial Intelligence amaze me.A simple idea-“Can Machines see the world, like humans?”has intrigued the whole world. These basic ideas may look appealing to anyone, but to me, the beauty lies in the struggle and hard work that is put in by people who have converted these ideas into reality. Machine Learning and Artificial intelligence can be applied to so many situations and I believe that these fields when utilised to their true potential can save the world.&lt;/p&gt;

&lt;p&gt;In my school days,I used to try my hands on every sport; every field be it drama, dance or debate.I strongly believe that a student must be an all-rounder to be successful in the true sense.Being a national level swimmer, I have learnt how to win and lose and realised that we human beings are much more capable of ourselves than we ever thought was imaginable and understood why the term “team” has been coined from the phrase “Together Everyone Achieves More”. Furthermore, participating in debates has taught me how to hold on to my decisions and how to accept others’ views as well.&lt;/p&gt;

&lt;p&gt;I was in my high school when I ran my first code. The code was the utmost basic one but the joy, incomparable.It’s strange but the happiness and satisfaction I receive from a successful code(no matter how many hours and days I’ve spent it on)seem to never decease.It is this zeal that urges me to try more, explore more and be more.&lt;/p&gt;

&lt;p&gt;“We can see only a short distance ahead, but we can see plenty that needs to be done.”–Alan Turing&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paavini Nanda</title>
   <link href="https://midas.iiitd.edu.in/team/paavini-nanda.html"/>
   <updated>2018-08-08T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/paavini-nanda</id>
   <content type="html">&lt;p&gt;I am an undergraduate student at NSIT, currently in my fourth year. My interests lie in machine learning and data mining.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dhruva Sahrawat</title>
   <link href="https://midas.iiitd.edu.in/team/dhruva-sahrawat.html"/>
   <updated>2018-08-07T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/dhruva-sahrawat</id>
   <content type="html">&lt;p&gt;I am a CSE undergrad at IIIT Delhi. I work primarily in Deep Learning, NLP and Computer Vision.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Raghav Kapoor</title>
   <link href="https://midas.iiitd.edu.in/team/Raghav-Kapoor.html"/>
   <updated>2018-08-05T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Raghav-Kapoor</id>
   <content type="html">&lt;p&gt;I am an undergraduate student from Netaji Subhas Institute of Technology, Delhi with great academic record and position and have been awarded merit scholarship for the same. I am a hardworking and passionate student and have keen interest in the field of Artificial Intellignce and currently working as a research intern in the MIDAS Labs IIITD where I work on projects related to Natural Language Processing (NLP), Deep Learning, Data Mining and Computer Vision. I have also published a research paper titled “Mind Your Language : Abuse and Offense Detection using Code-Switched Language” in the prestigious conference AAAI - 19.&lt;/p&gt;

&lt;p&gt;I am an avid learner, programmer and love problem solving and would wish to contribute using my cerebral abilities and skills for an intellectual experience in the field of programming. I have also interned in Goldman Sachs as a software analyst and have great experience in the field of coding. Furthermore, I have won many coding contests for which I have been awarded cash prizes and also a problem setter at various competitive coding websites. Apart from the academic interests, I also have a keen interest in swimming and debating, and have participated in many contests right from the school days. I strongly believe that one must be in a continuous process of learning as “Excellence is a continuous process and not an accident” - Dr. A.P.J Abdul Kalam.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Apoorv Bhardwaj</title>
   <link href="https://midas.iiitd.edu.in/team/Apoorv-Bhardwaj.html"/>
   <updated>2018-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Apoorv-Bhardwaj</id>
   <content type="html">&lt;p&gt;I am  an Undegraduate student at DTU, working as a Deep Learning intern. My interests include Natural Language Understanding, Computer Vison and various other sub-fields of AI. Non-academic interests include reading.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Vedant Bhatia</title>
   <link href="https://midas.iiitd.edu.in/team/vedant-bhatia.html"/>
   <updated>2018-08-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/vedant-bhatia</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Raghav Mehta</title>
   <link href="https://midas.iiitd.edu.in/team/raghav-mehta.html"/>
   <updated>2018-07-29T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/raghav-mehta</id>
   <content type="html">&lt;p&gt;I am a B.E. Information Technology Graduate from NSIT batch of 2018. My areas of interest lie in machine learning and foremost deep learning. I have been involved with research and projects in the same field. I’ve done some work in semi-supervised learning and GANs and published the same with TowardsDataScience.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Namrata Mukhija</title>
   <link href="https://midas.iiitd.edu.in/team/namrata-mukhija.html"/>
   <updated>2018-07-29T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/namrata-mukhija</id>
   <content type="html">&lt;p&gt;I am a 2018 B.E Information Technology graduate from NSIT, Delhi. I am currently working as a Software Engineer at Microsoft. My research interests revolve around Natural Language Processing, Computer Vision and Deep Learning. I love dancing, desserts, and cats!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Anmol Chugh</title>
   <link href="https://midas.iiitd.edu.in/team/anmol-chugh.html"/>
   <updated>2018-07-28T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/anmol-chugh</id>
   <content type="html">&lt;p&gt;I am an experienced engineer with a demonstrated history of working in the computer software industry. I am a strong engineering professional skilled in programming, algorithmic application and Computer Graphics.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Varnit Jain</title>
   <link href="https://midas.iiitd.edu.in/team/varnit-jain.html"/>
   <updated>2018-07-24T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/varnit-jain</id>
   <content type="html">&lt;p&gt;I’m an undergraduate student who likes to tinker with data and hardware. Love to use Data Science and HCI to solve problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Karan Dabas</title>
   <link href="https://midas.iiitd.edu.in/team/karan-dabas.html"/>
   <updated>2018-07-24T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/karan-dabas</id>
   <content type="html">&lt;p&gt;I am an undergraduate student at IIIT-Delhi (class of 2019). My research interest lies in Machine Learning, Natural Language Processing, Image Processing, Computational Social Science, Social Computing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Arnav Arora</title>
   <link href="https://midas.iiitd.edu.in/team/arnav-arora.html"/>
   <updated>2018-07-24T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/arnav-arora</id>
   <content type="html">&lt;p&gt;I’m a recent graduate from SRM Institute of Science and Technology, Chennai. I work on making machines understand language with the help of machine learning techniques. When I’m not reading research papers, you can find me playing with the closest street dog.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Aditya Kumar Pathak</title>
   <link href="https://midas.iiitd.edu.in/team/aditya-pathak.html"/>
   <updated>2018-07-24T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/aditya-pathak</id>
   <content type="html">&lt;p&gt;I have Completed my M.tech from IIIT Bhubaneswar, in the field of Natural Language Processing, machine learning, and deep learning. At present, I am working as a research intern at IIIT Delhi in the field of speech identification using deep learning. I am enthusiastic about learning new things and applying it in real world problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sanket Jain</title>
   <link href="https://midas.iiitd.edu.in/team/sanket-jain.html"/>
   <updated>2018-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/sanket-jain</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Hritwik Dutta</title>
   <link href="https://midas.iiitd.edu.in/team/hritwik.html"/>
   <updated>2018-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/hritwik</id>
   <content type="html">&lt;p&gt;I am a fourth year undergraduate student at NSIT. I am passionate about deep learning and Natural Language Processing.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ashutosh Pandey</title>
   <link href="https://midas.iiitd.edu.in/team/ashutosh-pandey.html"/>
   <updated>2018-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/ashutosh-pandey</id>
   <content type="html">&lt;p&gt;A post graduate from IIIT Delhi. Exploring opportunities on various optimal ways for multi-modal fusion of data.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>We are on FB and Twiter now</title>
   <link href="https://midas.iiitd.edu.in/news/social-media-links.html"/>
   <updated>2018-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/social-media-links</id>
   <content type="html">&lt;p&gt;We are on Facebook and Twitter now. &lt;a href=&quot;https://www.facebook.com/midasIIITD&quot;&gt;www.facebook.com/midasIIITD&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/midasIIITD&quot;&gt;www.twitter.com/midasIIITD&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/harnessing-ai-speech-reconstruction.html"/>
   <updated>2018-07-15T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/harnessing-ai-speech-reconstruction</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Speechreading involves looking, perceiving, and interpreting spoken symbols. It has a wide range of multimedia applications such as in surveillance, Internet telephony, and as an aid to a person with hearing impairments. However, most of the work in speechreading has been limited to text generation from silent videos. Recently, research has ventured into generating (audio) speech from silent video sequences but there have been no developments in using multiple cameras for speech generation. To this end, this paper presents the world’s first ever multi-view speech reading and reconstruction system. This work encompasses the boundaries of multimedia research by putting forth a model which leverages silent video feeds from multiple cameras recording the same subject to generate intelligent speech for a speaker. Initial results confirm the usefulness of exploiting multiple views in building an efficient speech reading and reconstruction system. It further shows the optimal placement of cameras which would lead to the maximum intelligibility of speech. Next, it lays out various innovative applications for the proposed system focusing on its potential prodigious impact in not just security arena but in many other multimedia analytics problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Vaishali got placed</title>
   <link href="https://midas.iiitd.edu.in/news/vaishali-placed.html"/>
   <updated>2018-07-15T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/vaishali-placed</id>
   <content type="html">&lt;p&gt;Congratulations Vaishali for getting placed in Qualcomm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper accepted at ACMMM2018</title>
   <link href="https://midas.iiitd.edu.in/news/acm-multi-speech-paper.html"/>
   <updated>2018-07-15T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/acm-multi-speech-paper</id>
   <content type="html">&lt;p&gt;A paper titled, “Harnessing AI for Speech Reconstruction using Multi-view Silent Video Feed”, got accepted in the Brave New Idea track of ACM Multimedia 2018 (approx 8% acceptance rate). Congratulation to authors: &lt;a href=&quot;/team/yaman.html&quot;&gt;Yaman Kumar&lt;/a&gt;, &lt;a href=&quot;/team/mayank.html&quot;&gt;Mayank Aggarwal&lt;/a&gt;, &lt;a href=&quot;/team/pratham.html&quot;&gt;Pratham Nawal&lt;/a&gt;, &lt;a href=&quot;http://research.nii.ac.jp/~satoh/&quot;&gt;Shin’ichi Satoh&lt;/a&gt;, &lt;a href=&quot;/team/rajiv-ratn-shah.html&quot;&gt;Rajiv Ratn Shah&lt;/a&gt;, &lt;a href=&quot;https://www.comp.nus.edu.sg/~rogerz/roger.html&quot;&gt;Roger Zimmerman&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Karmanya Aggarwal</title>
   <link href="https://midas.iiitd.edu.in/team/karmanya-aggarwal.html"/>
   <updated>2018-07-06T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/karmanya-aggarwal</id>
   <content type="html">&lt;p&gt;A developer at Gramener, I’m interested in the applications of Machine Learning to causes for social good&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Multimodal Social Media Analysis</title>
   <link href="https://midas.iiitd.edu.in/projects/project/Multimodal-Social-Media-Analysis.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/projects/project/Multimodal-Social-Media-Analysis</id>
   <content type="html">
&lt;p&gt;&lt;img src=&quot;/assets/images/projects/multimodal-social-media.jpg&quot; style=&quot;height: 100%; width: 100%; object-fit: contain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In recent years, a huge amount of user-generated content (UGC) online (e.g., text, images, and videos) is accumulated on the web. UGC available on different platforms helps social media companies in sensing feedback, opinion, and interests of users, and provide services accordingly. However, due to the vast amount of data and inherent noise in social media content, often it is difficult to extract useful information from a single modality. Thus, it is essential to leverage information from multiple modalities to reduce noise from social media content. We leverage both multimedia content and contextual information to provide solutions to several important problems such as fake news detection, trolling detection, hate-speech detection, popularity predictions of photos, soundtrack recommendations for videos, and event summarization. At MIDAS@IIITD, we focus on building efficient fusion mechanisms using deep neural networks techniques which can help social media companies to provide a better service to their users. Our recent papers on multimodal social media analysis are published in top-tier conferences such as ACM Multimedia, WWW, NAACL, etc.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Lipreading and Speech Reconstruction</title>
   <link href="https://midas.iiitd.edu.in/projects/project/Lipreading-and-Speech-Reconstruction.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/projects/project/Lipreading-and-Speech-Reconstruction</id>
   <content type="html">
&lt;p&gt;&lt;img src=&quot;/assets/images/projects/lipper.jpg&quot; style=&quot;height: 100%; width: 100%; object-fit: contain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speechreading broadly involves looking, perceiving, and interpreting spoken symbols. It has a wide range of multimedia applications, such as surveillance, Internet telephony, and as an aid to a person with hearing impairments. However, most of the work in speechreading has been limited to text generation from silent videos. Recently, research has ventured into generating (audio) speech from silent video sequences but there have been no developments in using multiple cameras for speech generation. To this end, this project encompasses the boundaries of multimedia research by putting forth a model which leverages silent video feeds from multiple cameras recording the same subject to generate intelligent speech for a speaker. Initial results confirm the usefulness of exploiting multiple views in building an efficient speech reading and reconstruction system. It further shows the optimal placement of cameras which would lead to the maximum intelligibility of speech. At MIDAS@IIITD, we plan to leverage the proposed system in various innovative applications and focus on its potential prodigious impact in not just security arena but in many other multimedia analytics problems. Our recent paper on speech reconstruction from silent videos is published in ACM Multimedia, a premier Multimedia conference.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Harnessing AI for Health Care</title>
   <link href="https://midas.iiitd.edu.in/projects/project/Harnessing-AI-for-Health-Care.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/projects/project/Harnessing-AI-for-Health-Care</id>
   <content type="html">
&lt;p&gt;&lt;img src=&quot;/assets/images/projects/ai-healtcare.jpg&quot; style=&quot;height: 100%; width: 100%; object-fit: contain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In recent years, advances in artificial intelligence techniques haveyielded immense success in computer vision, natural language processing, and speech processing. Healthcare is also one of the areas which got much benefited through this. Mining social media messages for health and drug-related information has received significant interest in pharmacovigilance research. For instance, an analysis of social media text (e.g., tweets, posts, and comments) using natural language processing and machine learning techniques helps in finding the adverse drug reactions, suicidal ideation, depression detection, medical information extraction, etc. Moreover, computer vision and machine learning techniques help the automatic detection of different disease from tissue images. For instance, it has shown immense success in the detection of cancer, diabetes, kidney failure, etc. Furthermore, speech processing in conjunction with artificial intelligence has shown great success in the treatment of people. Moreover, artificial intelligence helps in building systems for people with different abilities. At MIDAS@IIITD, we focus on several such interesting research problems (e.g., kidney glomeruli classification, automatic kidney fibrosis assessment, adverse drug reactions, and suicidal ideation ) leveraging deep learning techniques. Our recent papers in this area are published in top-tier conferences and journals such as IEEE Intelligent Systems, NAACL, etc.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Event Detection and Summarization</title>
   <link href="https://midas.iiitd.edu.in/projects/project/Event-Detection-and-Summarization.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/projects/project/Event-Detection-and-Summarization</id>
   <content type="html">
&lt;p&gt;&lt;img src=&quot;/assets/images/projects/eventbuilder.jpg&quot; style=&quot;height: 100%; width: 100%; object-fit: contain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With the advent of smartphones and auto-uploaders, user-generated content (e.g., tweets, photos, and videos) uploads on social media have become more numerous and asynchronous. Thus, it is difficult and time taking for users to manually search (detect) interesting events. It requires for social media companies to automatically detect events and subsequently recommend them to their users. An automatic event detection is also very useful in an efficient search and retrieval of user-generated content. Furthermore, since the number of users and events on event-based social networks (EBSN) is increasing rapidly, it is not feasible for users to manually find the personalized events of their interest. We would like to further explore events on EBSN such as Meetup for different multimedia analytics projects such as recommending events, groups, and friends to users. At MIDAS@IIITD, we would like to use Deep Neural Network (DNN) technologies due to their immense success to address these interesting problems. Our recent papers on event detection and summarization are published in top-tier conferences and journals such as Knowledge-Based Systems, ACM Multimedia, ACM ICMR, etc.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Code-Switched Language Processing</title>
   <link href="https://midas.iiitd.edu.in/projects/project/Code-Switched-Language-Processing.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/projects/project/Code-Switched-Language-Processing</id>
   <content type="html">
&lt;p&gt;&lt;img src=&quot;/assets/images/projects/code-switched-language.jpg&quot; style=&quot;height: 100%; width: 100%; object-fit: contain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The exponential rise of social media websites like Twitter, Facebook and Reddit in linguistically diverse geographical regions has led to hybridization of popular native languages with English in an effort to ease communication. For instance, Hinglish is formed of the words spoken in Hindi language but written in Roman script instead of the Devanagari script. It is a pronunciation based bi-lingual language that has no fixed grammar rules. Therefore, it is difficult to derive any useful information from such code-switched languages. Therefore, it necessitates social media companies to build models that can extract useful information from such languages. This will be useful in a number of applications such as detecting offensive languages, understanding feedback, opinions, and sentiments of users towards some product, news, events, policies, etc. At MIDAS@IIITD, we focus on building deep learning models which can extract useful information and automatically perform efficient classifications from code-switched languages such as Hinglish. For instance, our recent paper on detecting offensive language in Hinglish tweets is published in ACL, a premier NLP conference.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MR2AMC</title>
   <link href="https://midas.iiitd.edu.in/events/event/MR2AMC.html"/>
   <updated>2018-07-03T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/events/event/MR2AMC</id>
   <content type="html">
&lt;p&gt;MR2AMC is a series of workshops on Multimodal Representation, Retrieval, and Analysis of Multimedia Content organized by the MIDAS lab in IIIT-Delhi. MIDAS stands for Multimodal Digital Media Analysis Lab and it consists a group of researchers who study, analyze, and build different multimedia systems for society leveraging multimodal information. The first iteration of the workshop held in conjunction with the IEEE MIPR conference. The second iteration of the workshop will be held in conjunction with the 20th IEEE International Conference on Multimedia in Taichung, Taiwan. This year’s workshop theme is social media. Thus, MR2AMC aims to provide an international forum for researchers in the field of multimedia data processing, analysis, search, mining, and management leveraging multimodal information in social media. This workshop will provide a forum to researchers and practitioners from both academia and industry for original research contributions and practical system design, implementation, and applications of multimodal multimedia information processing, mining, representation, management, and retrieval. MR2AMC 2018 invites research papers in the area of multimodal multimedia content analysis, search and retrieval, semantic computing, and affective computing. Accepted papers of MR2AMC 2018 will be published as part of the workshop proceedings in the IEEE Digital Library. Extended versions of the accepted workshop papers will be invited for publication in &lt;a href=&quot;https://link.springer.com/journal/12559&quot;&gt;Springer Cognitive Computation&lt;/a&gt; and &lt;a href=&quot;https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10207&quot;&gt;IEEE Computational Intelligence Magazine&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Himanshu Aggarwal</title>
   <link href="https://midas.iiitd.edu.in/team/himanshu-aggarwal.html"/>
   <updated>2018-07-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/himanshu-aggarwal</id>
   <content type="html">&lt;p&gt;I’m a post-grad student at IIIT Delhi. Currently, I am working on cross-modal retrieval systems. My research interest include information retrieval and machine learning. I like reading research papers and paiting.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/learning-and-fusing.html"/>
   <updated>2018-07-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/learning-and-fusing</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Convolutional Neural Networks (CNNs) have been widely applied to audio classification recently where promising results have been obtained. Previous CNN-based systems mostly learn from two-dimensional time-frequency representations such as MFCC and spectrogram, which may tend to emphasize more on the background noise of the scene. To learn the key acoustic events, we introduce a three-dimensional CNN to emphasize on the different spectral characteristics from neighboring regions in spatial-temporal domain. A novel acoustic scene classification system based on multimodal deep fusion has been proposed in this paper, where three CNNs have been presented to perform 1D raw waveform modeling, 2D time-frequency image modeling, and 3D spatial-temporal dynamics modeling, respectively. The learnt features have been shown to be highly complementary to each other, leading to significant classification improvements based on feature fusion. A new double fusion scheme, which takes advantages of both early fusion and late fusion, is proposed to further boost the system’s performance. Comprehensive experiments have been conducted on the DCASE16 dataset for acoustic scene classification. Experimental results demonstrate the effectiveness of our proposed approach, as our solution achieves the state-of-the-art classification rates and improves the mean accuracy by 2.3% ∼ 9.2% compared to the top ranked systems in the DCASE16 challenge.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper accepted at ACMMM2018</title>
   <link href="https://midas.iiitd.edu.in/news/acm-multi-fusing-paper.html"/>
   <updated>2018-07-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/acm-multi-fusing-paper</id>
   <content type="html">&lt;p&gt;MIDAS founder and collaborators, &lt;a href=&quot;/team/rajiv-ratn-shah.html&quot;&gt;Rajiv Ratn Shah&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com.sg/citations?user=TRfTdBAAAAAJ&amp;amp;hl=en&quot;&gt;Yifang Yin&lt;/a&gt;, and &lt;a href=&quot;https://www.comp.nus.edu.sg/~rogerz/roger.html&quot;&gt;Roger Zimmermann&lt;/a&gt; published a full paper titled, “Learning and Fusing Multimodal Deep Features for Acoustic Scene Categorization”, in the ACM Multimedia 2018, a premier conference for multimedia research.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Hitkul, Shivangi and Himanshu got internship at NII</title>
   <link href="https://midas.iiitd.edu.in/news/hitkul-shivangi-nii.html"/>
   <updated>2018-06-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/hitkul-shivangi-nii</id>
   <content type="html">&lt;p&gt;MIDAS students, &lt;a href=&quot;/team/hitkul.html&quot;&gt;Hitkul&lt;/a&gt;, &lt;a href=&quot;/team/shivangi.html&quot;&gt;Shivangi Singhal&lt;/a&gt;, and Himanshu Aggarwal, got selected for six months fully funded internship at &lt;a href=&quot;https://www.nii.ac.jp/en/&quot;&gt;National Institute of Informatics&lt;/a&gt;, Tokyo, Japan.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Dr. Debanjan, is now an adjunct faculty IIIT-Delhi</title>
   <link href="https://midas.iiitd.edu.in/news/debanjan-appointed-as-adjunct-faculty.html"/>
   <updated>2018-06-22T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/debanjan-appointed-as-adjunct-faculty</id>
   <content type="html">&lt;p&gt;MIDAS collaborator, &lt;a href=&quot;https://www.linkedin.com/in/debanjanmahata/&quot;&gt;Dr Debanjan Mahata&lt;/a&gt;, is appointed as an adjunct faculty at &lt;a href=&quot;http://iiitd.ac.in/&quot;&gt;IIIT-Delhi&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Detecting Offensive Tweets in Hindi-English Code-Switched Language</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/detecting-offensive-tweets.html"/>
   <updated>2018-06-20T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/detecting-offensive-tweets</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;The exponential rise of social media websites
like Twitter, Facebook and Reddit in
linguistically diverse geographical regions
has led to hybridization of popular native
languages with English in an effort to ease
communication. The paper focuses on the
classification of offensive tweets written in
Hinglish language, which is a portmanteau
of the Indic language Hindi with the Roman
script. The paper introduces a novel
tweet dataset, titled Hindi-English Offensive
Tweet (HEOT) dataset, consisting
of tweets in Hindi-English code switched
language split into three classes: nonoffensive,
abusive and hate-speech. Further,
we approach the problem of classification
of the tweets in HEOT dataset using
transfer learning wherein the proposed
model employing Convolutional Neural
Networks is pre-trained on tweets in English
followed by retraining on Hinglish
tweets.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Anjali Bhavan</title>
   <link href="https://midas.iiitd.edu.in/team/anjali-bhavan.html"/>
   <updated>2018-06-19T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/anjali-bhavan</id>
   <content type="html">&lt;p&gt;I am an undergraduate student at Delhi Technological University. I like to read, write and spend more hours than sustainable writing code.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shivangi, got the ACM India Grad Cohort 2018</title>
   <link href="https://midas.iiitd.edu.in/news/shivangi-acm-india-grad-cohort-award.html"/>
   <updated>2018-06-19T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/shivangi-acm-india-grad-cohort-award</id>
   <content type="html">&lt;p&gt;MIDAS student, &lt;a href=&quot;/team/shivangi.html&quot;&gt;Shivangi Singhal&lt;/a&gt;, got selected for the &lt;a href=&quot;https://www.cse.iitb.ac.in/~acmindiacohort/&quot;&gt;ACM India Grad Cohort 2018&lt;/a&gt; which will be held in IIIT Bombay.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Sarthak Anand</title>
   <link href="https://midas.iiitd.edu.in/team/sarthak-anand.html"/>
   <updated>2018-06-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/sarthak-anand</id>
   <content type="html">&lt;p&gt;YOur introduction here.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Key2Vec: Automatic Ranked Keyphrase Extraction from Scientific Articles using Phrase Embeddings</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/key2vec.html"/>
   <updated>2018-06-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/key2vec</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Keyphrase extraction is a fundamental task
in natural language processing that facilitates
mapping of documents to a set of representative
phrases. In this paper, we present an unsupervised
technique (Key2Vec) that leverages
phrase embeddings for ranking keyphrases
extracted from scientific articles. Specifically,
we propose an effective way of processing
text documents for training multi-word
phrase embeddings that are used for thematic
representation of scientific articles and ranking
of keyphrases extracted from them using
theme-weighted PageRank. Evaluations are
performed on benchmark datasets producing
state-of-the-art results.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>#phramacovigilance - Exploring Deep Learning Techniques for Identifying Mentions of Medication Intake from Twitter</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/phramacovigilance.html"/>
   <updated>2018-05-17T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/phramacovigilance</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Mining social media messages for health and
drug related information has received significant
interest in pharmacovigilance research.
Social media sites (e.g., Twitter), have been
used for monitoring drug abuse, adverse reactions
of drug usage and analyzing expression
of sentiments related to drugs. Most of these
studies are based on aggregated results from
a large population rather than specific sets of
individuals. In order to conduct studies at an
individual level or specific cohorts, identifying
posts mentioning intake of medicine by
the user is necessary. Towards this objective,
we train different deep neural network classification
models on a publicly available annotated
dataset and study their performances
on identifying mentions of personal intake of
medicine in tweets. We also design and train
a new architecture of a stacked ensemble of
shallow convolutional neural network (CNN)
ensembles. We use random search for tuning
the hyperparameters of the models and share
the details of the values taken by the hyperparameters
for the best learnt model in different
deep neural network architectures. Our system
produces state-of-the-art results, with a microaveraged
F-score of 0.693.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hitkul joined as PhD</title>
   <link href="https://midas.iiitd.edu.in/news/Hitkul-joined-as-Phd.html"/>
   <updated>2018-05-16T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/Hitkul-joined-as-Phd</id>
   <content type="html">&lt;p&gt;MIDAS intern, &lt;a href=&quot;/team/hitkul.html&quot;&gt;Hitkul&lt;/a&gt;, enrolled for PhD under the supervision of &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Prof Rajiv Ratn Shah&lt;/a&gt; and &lt;a href=&quot;https://www.iiitd.ac.in/pk&quot;&gt;Prof PK&lt;/a&gt; at IIITD.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>#phramacovigilance is live now</title>
   <link href="https://midas.iiitd.edu.in/news/phramacovigilance.html"/>
   <updated>2018-05-16T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/#phramacovigilance</id>
   <content type="html">&lt;p&gt;We made our paper titled, “ #phramacovigilance - Exploring Deep Learning Techniques for Identifying Mentions of Medication Intake from Twitter”, online on Arxiv to the research community.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper accepted in IEEE, ACSA. </title>
   <link href="https://midas.iiitd.edu.in/news/IEEE-Intelligent-Systems-paper-accepted.html"/>
   <updated>2018-04-27T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/IEEE-Intelligent-Systems-paper-accepted</id>
   <content type="html">&lt;p&gt;MIDAS founder, &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Dr. Rajiv Ratn Shah&lt;/a&gt;, and collaborator, &lt;a href=&quot;https://www.linkedin.com/in/debanjanmahata/&quot;&gt;Dr. Debanjan Mahata&lt;/a&gt;, got their research paper, titled “Did you take the pill? – Detecting Personal Intake of Medicine from Twitter”, accepted in the special chapter of IEEE Intelligent Systems on Affective Computing and Sentiment Analysis.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Aspect-Based Financial Sentiment Analysis using Deep Learning</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Aspect-Based-Financial-Sentiment-Analysis.html"/>
   <updated>2018-04-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Aspect-Based-Financial-Sentiment-Analysis</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Aspect based sentiment analysis aims to detect an aspect (i.e. features) in a given text and then perform sentiment analysis of the text with respect to that aspect. This paper aims to give a solution for the FiQA 2018 challenge subtask 1. We perform aspect-based sentiment analysis on the microblogs and headlines of financial domain. We use a multi-channel convolutional neural network for sentiment analysis and a recurrent neural network with bidirectional long short-term memory units to extract aspect from a given headline or microblog. Our proposed model produces a weighted average F1 score of 0.69 for the aspect extraction task and predicts sentiment intensity scores with a mean squared error of 0.112 on 10-fold cross validation. We believe that the developed system has direct applications in the financial domain.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Theme-weighted Ranking of Keywords from Text Documents using Phrase Embeddings</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/theme-weighted-ranking.html"/>
   <updated>2018-04-22T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/theme-weighted-ranking</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Keyword extraction is a fundamental task in natural
language processing that facilitates mapping of documents to
a concise set of representative single and multi-word phrases.
Keywords from text documents are primarily extracted using
supervised and unsupervised approaches. In this paper, we
present an unsupervised technique that uses a combination of
theme-weighted personalized PageRank algorithm and neural
phrase embeddings for extracting and ranking keywords. We
also introduce an efficient way of processing text documents and
training phrase embeddings using existing techniques. We share
an evaluation dataset derived from an existing dataset that is used
for choosing the underlying embedding model. The evaluations
for ranked keyword extraction are performed on two benchmark
datasets comprising of short abstracts (Inspec), and long scientific
papers (SemEval 2010), and is shown to produce results better
than the state-of-the-art systems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Multimodal Approach to Predict Social Media Popularity</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/multimodal-social-media-popularity.html"/>
   <updated>2018-04-22T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/multimodal-social-media-popularity</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Multiple modalities represent different aspects by which
information is conveyed by a data source. Modern day social
media platforms are one of the primary sources of multimodal
data, where users use different modes of expression
by posting textual as well as multimedia content such as images
and videos for sharing information. Multimodal information
embedded in such posts could be useful in predicting
their popularity. To the best of our knowledge, no such
multimodal dataset exists for the prediction of social media
photos. In this work, we propose a multimodal dataset
consisiting of content, context, and social information for
popularity prediction. Specifically, we augment the SMPT1
dataset for social media prediction in ACM Multimedia
grand challenge 2017 with image content, titles, descriptions,
and tags. Next, in this paper, we propose a multimodal
approach which exploits visual features (i.e., content
information), textual features (i.e., contextual information),
and social features (e.g., average views and group counts)
to predict popularity of social media photos in terms of view
counts. Experimental results confirm that despite our multimodal
approach uses the half of the training dataset from
SMP-T1, it achieves comparable performance with that of
state-of-the-art.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Rajiv, got the Heidelberg Laureate Forum fellowship 2018</title>
   <link href="https://midas.iiitd.edu.in/news/rajiv-got-Heidelberg-Laureate-Forum-fellowship.html"/>
   <updated>2018-04-19T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/rajiv-got-Heidelberg-Laureate-Forum-fellowship</id>
   <content type="html">&lt;p&gt;MIDAS founder, &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Dr. Rajiv Ratn Shah&lt;/a&gt;, got selected for the Heidelberg Laureate Forum fellowship 2018 which will be held in Heidelberg, Germany.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Prof. Rada delivere keynote in MR2AMC</title>
   <link href="https://midas.iiitd.edu.in/news/prof-Rada-delivered-keynote.html"/>
   <updated>2018-04-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/prof-Rada-delivered-keynote</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://web.eecs.umich.edu/~mihalcea/&quot;&gt;Prof Rada Mihalcea&lt;/a&gt; from University of Michigan has delivered a keynote on “Multimodal Sensing of Human Behavior” in the MR2AMC workshop organized by MIDAS.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Dr. Rajiv organized MR2AMC </title>
   <link href="https://midas.iiitd.edu.in/news/MR2AMC-worshop-conducted.html"/>
   <updated>2018-04-11T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/MR2AMC--worshop-conducted</id>
   <content type="html">&lt;p&gt;MIDAS founder, &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Dr. Rajiv Ratn Shah&lt;/a&gt;, organized MR2AMC workshop in conjunction with &lt;a href=&quot;http://www.ieee-mipr.org/workshop_MBDDL.html&quot;&gt;IEEE MIPR conference&lt;/a&gt; at Miami, Florida, USA.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>NII is our new collaborator</title>
   <link href="https://midas.iiitd.edu.in/news/NII-collab.html"/>
   <updated>2018-03-14T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/NII-collab</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://research.nii.ac.jp/~satoh/&quot;&gt;Professor Shin’ichi Satoh&lt;/a&gt; and Prof Henri Angelino from the &lt;a href=&quot;https://www.nii.ac.jp/en/&quot;&gt;National Institute of Informatics (NII), Japan&lt;/a&gt; visited MIDAS@IIITD  to sign MOU between NII and &lt;a href=&quot;http://iiitd.ac.in/&quot;&gt;IIIT-Delhi&lt;/a&gt; to establish research collaboration between two institutes. MIDAS founder, &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Prof Rajiv Ratn Shah&lt;/a&gt;, is the contact person at IIIT-Delhi for this research collaboration.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Ramit Sawhney</title>
   <link href="https://midas.iiitd.edu.in/team/ramit-sawhney.html"/>
   <updated>2018-03-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/ramit-sawhney</id>
   <content type="html">&lt;p&gt;I’m currently working as a Core Engineering Software Developer at Tower Research Capital on Machine Learning problems. A recent graduate and department rank 1 from NSIT, Delhi, my research interests include Natural Language Processing, Evolutionary Computation and Biomedical and Financial applications of Machine Learning.&lt;/p&gt;

&lt;p&gt;Having previously worked with Samsung Research, IBM Research, Georgia Institute of Technology, The University of Texas complement my interests and align with my goal of solving problems impacting millions, progressively and collaboratively within MIDAS.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper accepted in WWW'18</title>
   <link href="https://midas.iiitd.edu.in/news/WWW-2018-paper-accept.html"/>
   <updated>2018-03-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/WWW-2018-paper-accept</id>
   <content type="html">&lt;p&gt;MIDAS students, &lt;a href=&quot;/team/hitkul.html&quot;&gt;Hitkul&lt;/a&gt; and &lt;a href=&quot;/team/shivangi.html&quot;&gt;Shivangi Singhal&lt;/a&gt;, got their research paper, titled “Aspect-Based Financial Sentiment Analysis using Deep Learning”, accepted in &lt;a href=&quot;https://www2018.thewebconf.org/&quot;&gt;WWW 2018&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Paper accepted in NAACL 2018</title>
   <link href="https://midas.iiitd.edu.in/news/NAACL-2018-paper-accept.html"/>
   <updated>2018-03-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/NAACL-2018-paper-accept</id>
   <content type="html">&lt;p&gt;MIDAS founder, &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Dr. Rajiv Ratn Shah&lt;/a&gt;, and collaborator, &lt;a href=&quot;https://www.linkedin.com/in/debanjanmahata/&quot;&gt;Dr. Debanjan Mahata&lt;/a&gt;, got their research paper, titled “Key2Vec: Automatic Ranked Keyphrase Extraction from Scientific Articles Using Phrase Embeddings”, accepted in &lt;a href=&quot;http://naacl2018.org/&quot;&gt;NAACL 2018&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Paper accepted at MR2AMC 2018</title>
   <link href="https://midas.iiitd.edu.in/news/mr2amc-paper-theme-weighted-ranking.html"/>
   <updated>2018-02-05T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/mr2amc-paper-theme-weighted-ranking</id>
   <content type="html">&lt;p&gt;Our paper titled, “A Multimodal Approach to Predict Social Media Popularity “, got accepted in the MR2AMC workshop 2018&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Paper accepted at MR2AMC 2018</title>
   <link href="https://midas.iiitd.edu.in/news/mr2amc-paper-social-media-popularity.html"/>
   <updated>2018-02-05T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/mr2amc-paper-social-media-popularity</id>
   <content type="html">&lt;p&gt;Our paper titled, “A Multimodal Approach to Predict Social Media Popularity “, got accepted in the MR2AMC workshop 2018&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Did you take the #pill? - Detecting Personal Intake of Medicine from Twitter</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/pill-intake.html"/>
   <updated>2018-02-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/pill-intake</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Mining social media messages such as tweets, blogs, and Facebook posts for health and drug related information has received significant interest in pharmacovigilance research. Social media sites (e.g., Twitter), have been used for monitoring drug abuse, adverse reactions of drug usage and analyzing expression of sentiments related to drugs. Most of these studies are based on aggregated results from a large population rather than specific sets of individuals. In order to conduct studies at an individual level or specific cohorts, identifying posts mentioning intake of medicine by the user is necessary. Towards this objective we develop a classifier for identifying mentions of personal intake of medicine in tweets. We train a stacked ensemble of shallow convolutional neural network (CNN) models on an annotated dataset. We use random search for tuning the hyper-parameters of the CNN models and present an ensemble of best models for the prediction task. Our system produces state-of-the-art result, with a micro-averaged F-score of 0.693. We believe that the developed classifier has direct uses in the areas of psychology, health informatics, pharmacovigilance and affective computing for tracking moods, emotions and sentiments of patients expressing intake of medicine in social media.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Feature-based Map Matching for Low-Sampling-Rate GPS Trajectories</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Feature-based-Map-Matching.html"/>
   <updated>2018-02-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Feature-based-Map-Matching</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;With the increasing availability of GPS-equipped mobile devices, location-based services have become an
integral part of people’s everyday life. Among one of the initial steps of positioning data management, map
matching aims to reduce the uncertainty in a trajectory by matching the GPS points to the road network on
a digital map. Most existing work has focused on estimating the likelihood of a candidate route based on the
GPS observations, while neglecting to model the probability of a route choice from the perspective of drivers.
In this work, we propose a novel feature-based map matching algorithm that estimates the cost of a candidate
route based on both GPS observations and human factors. To take human factors into consideration is highly
important especially when dealing with low sampling rate data where most of the movement details are lost.&lt;/p&gt;

&lt;p&gt;Additionally, we simultaneously analyze a subsequence of coherent GPS points by utilizing a new segment-
based probabilistic map matching strategy, which is less susceptible to the noisiness of the positioning data.&lt;/p&gt;

&lt;p&gt;We have evaluated both the offline and the online versions of our proposed approach on a public large-scale
GPS dataset, which consists of 100 trajectories distributed all over the world. The experimental results show
that our method is robust to sparse data with large sampling intervals (e.g., 60 s ∼ 300 s) and challenging track
features (e.g., u-turns and loops). Measurements including map matching accuracy and system efficiency have
been thoroughly evaluated and discussed. Compared with two state-of-the-art map matching algorithms,
our method substantially reduces the route mismatch error by 6.4% ∼ 32.3% (either offline or online with the
window size set to 360 s) with a slight increase in terms of the processing time. The experimental results show
that our proposed method obtains the state-of-the-art map matching results in all the different combinations
of sampling rates and challenging features.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Workshop proposal accepted</title>
   <link href="https://midas.iiitd.edu.in/news/MR2AMC-workshop.html"/>
   <updated>2018-01-30T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/MR2AMC-workshop</id>
   <content type="html">&lt;p&gt;MIDAS workshop proposal, MR2AMC, is accepted in the &lt;a href=&quot;http://www.ieee-mipr.org/workshop_MBDDL.html&quot;&gt;IEEE MIPR conference&lt;/a&gt; which will be held at Miami, Florida, USA.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Geometry-based Localization for GPS Outage in Vehicular Cyber Physical Systems</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Geometry-Based-Localization.html"/>
   <updated>2018-01-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Geometry-Based-Localization</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Vehicular localization has witnessed significant attention due to the growing number of location-based services in vehicular cyber physical systems (VCPS). In vehicular localization, GPS outage is a challenging issue considering the growing urbanization including high rise buildings, multilevel flyovers and bridges. GPS-free and GPS-assisted cooperative localization techniques have been suggested in the literature for GPS outage. Due to the cost of infrastructure in GPS-free techniques, and the absence of location aware neighbors in cooperative techniques, efficient and scalable localization is a challenging task in VCPS. In this context, this paper proposes a geometry-based localization for GPS outage in VCPS (GeoLV). It is a GPS-assisted localization which reduces location-aware neighbor constraint of cooperative localization. GeoLV utilizes mathematical geometry to estimate vehicle location focusing on vehicular dynamics and road trajectory. The static and dynamic relocations are performed to reduce the impact of GPS outage on location-based services. A case study based comparative performance evaluation has been carried out to assess the efficiency and scalability of GeoLV. It is evident from the results that GeoLV handles both shorter and longer GPS outage problem better than the state-of-the-art techniques in VCPS.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Meghna P Ayyar</title>
   <link href="https://midas.iiitd.edu.in/team/meghna-p-ayyar.html"/>
   <updated>2018-01-05T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/meghna-p-ayyar</id>
   <content type="html">&lt;p&gt;The future is with Intelligent and Autonomous System capable of behaving akin to humans. With this belief I have decided to pursue my interest in coupling
Computer Vision, Machine Vision and Deep learning to create practical applications and making current techniques more intelligent. I have been a researcher at MIDAS since January 2018 and have worked on many projects and published at International Conferences like IEEE WACV, ISM and ALW, SMM4H at EMNLP. I am currently a Master’s student at the Erasmus Mundus Joint Master’s Degree in Image Processing and Computer Vision (IPCV). Reach out to me on my email ID for collaborating on projects involving deep learning, computer vision, bio medical images and other machine learning  or even to just have discussions and debates about all the great ideas that may pop into your mind.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shivangi joined as PhD</title>
   <link href="https://midas.iiitd.edu.in/news/shivangi-joined.html"/>
   <updated>2018-01-02T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/shivangi-joined</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/team/shivangi.html&quot;&gt;Shivangi Singhal&lt;/a&gt; joined as the first PhD student of the MIDAS lab under the supervision of &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Prof Rajiv Ratn Shah&lt;/a&gt; and &lt;a href=&quot;https://sites.google.com/site/tanmoychakra88/&quot;&gt;Prof Tanmoy Chakraborty&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Hitkul joined as intern</title>
   <link href="https://midas.iiitd.edu.in/news/hitkul-joined.html"/>
   <updated>2018-01-02T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/hitkul-joined</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/team/hitkul.html&quot;&gt;Hitkul&lt;/a&gt; joined as the first intern of the MIDAS lab under the supervision of &lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Prof Rajiv Ratn Shah&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Dr. Yifang Yin</title>
   <link href="https://midas.iiitd.edu.in/team/yin.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/yin</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Dr. Yi Yu</title>
   <link href="https://midas.iiitd.edu.in/team/yi-yu.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/yi-yu</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Yaman</title>
   <link href="https://midas.iiitd.edu.in/team/yaman.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/yaman</id>
   <content type="html">&lt;p&gt;I am a Ph.D. student in Computer Science at MIDAS-Lab (website rarely updated) in IIIT-D, advised by Prof. Rajiv Ratn Shah.&lt;/p&gt;

&lt;p&gt;My research revolves around Adversarial Networks, Meta-learning, QA and Speech. I am particularly interested in the business and public policy side of these things.&lt;/p&gt;

&lt;p&gt;I am also an Artificial Intelligence research scholar for companies like Benesse Corp and Berlitz Inc.&lt;/p&gt;

&lt;p&gt;In the daytime, I churn out software for Adobe.&lt;/p&gt;

&lt;p&gt;You can get more info about me by checking out the links above.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Vaishali Dabral</title>
   <link href="https://midas.iiitd.edu.in/team/vaishali.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/vaishali</id>
   <content type="html">&lt;p&gt;Pursuing master’s in computer science at IIITD and working on High-performance computing, Multimedia Computing and Data Science.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Tushar Jain</title>
   <link href="https://midas.iiitd.edu.in/team/tushar.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/tushar</id>
   <content type="html">&lt;p&gt;Hi , I am working on Event Analysis using multimodal data&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Tanmoy Chakraborty</title>
   <link href="https://midas.iiitd.edu.in/team/tanmoy.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/tanmoy</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>SIMRA SHAHID</title>
   <link href="https://midas.iiitd.edu.in/team/simra.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/simra</id>
   <content type="html">&lt;p&gt;The world has problems and we as coders have solutions. An innovative coder with the motive to bring about solutions, is what I go by. With my creativity and dedication, I believe I can bring about changes in the world and comfort in everyone’s lives.&lt;/p&gt;

&lt;p&gt;Its all about making the unknown known.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Shubham Thakral</title>
   <link href="https://midas.iiitd.edu.in/team/shubham-thakral.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/shubham-thakral</id>
   <content type="html">&lt;p&gt;I’m Shubham, a software enthusiast and always willing to learn and try out new things. Some time back machine learning caught my eye and here I’m learning and implementing stuff with the interesting and intriguing concepts of deep learning and machine learning. Apart from tech, music, particularly English pop is what I relish listening to.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Shree Gopal Sharma</title>
   <link href="https://midas.iiitd.edu.in/team/shree-gopal.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/shree-gopal</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Shivangi Singhal</title>
   <link href="https://midas.iiitd.edu.in/team/shivangi.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/shivangi</id>
   <content type="html">&lt;p&gt;My name is Shivangi Singhal. I am from Delhi. I have completed my undergraduation from University of Delhi and my masters from South Asian University. I joined MIDAS in January 2018 as a Phd Research Scholar.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Shin’ichi Satoh</title>
   <link href="https://midas.iiitd.edu.in/team/satho.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/satho</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Mohammad Salik</title>
   <link href="https://midas.iiitd.edu.in/team/salik.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/salik</id>
   <content type="html">&lt;p&gt;Hey Guys! I am a coding enthusiast who loves solving algorithmic problems. My research interests include NLP and complex algorithms analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sahil Chopra</title>
   <link href="https://midas.iiitd.edu.in/team/sahil.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/sahil</id>
   <content type="html">&lt;p&gt;I am final year,undergrad student at MSIT ,My research interest includes deep learning ,nlp and its application.I am an avid reader and madrid fan.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Rohit Jain</title>
   <link href="https://midas.iiitd.edu.in/team/rohit.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/rohit</id>
   <content type="html">&lt;p&gt;I am Rohit Jain from NSIT currently finished my 3rd year
I am doing intern currently during the summers at Intuit , Bangalore.I have worked on the problem of LipReading taken as a multimodal multimedia problem and have co-authored a paper with yaman, Salik, Prof Rajiv and Prof Zimmerman .I love playing sports, traveling , meeting new people.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Roger Zimmermann</title>
   <link href="https://midas.iiitd.edu.in/team/roger.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/roger</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Rajiv Ratn Shah</title>
   <link href="https://midas.iiitd.edu.in/team/rajiv-ratn-shah.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/rajiv-ratn-shah</id>
   <content type="html">&lt;p&gt;Rajiv Ratn Shah currently works as an Assistant Professor in the Department of Computer Science and Engineering (joint appointment with the Department of Human-centered Design) at IIIT-Delhi. He is the founder of MIDAS lab at IIIT-Delhi. He received his Ph.D. in computer science from the National University of Singapore, Singapore. Before joining IIIT-Delhi, he worked as a Research Fellow in Living Analytics Research Center (LARC) at the Singapore Management University, Singapore. Prior to completing his Ph.D., he received his M.Tech. and M.C.A. degrees in Computer Applications from the Delhi Technological University, Delhi and Jawaharlal Nehru University, Delhi, respectively. He has also received his B.Sc. in Mathematics (Honors) from the Banaras Hindu University, Varanasi. Dr. Shah is the recipient of several awards, including the prestigious Heidelberg Laureate Forum (HLF) and European Research Consortium for Informatics and Mathematics (ERCIM) fellowships. He has also received the best paper award in the IWGS workshop at the ACM SIGSPATIAL conference 2016, San Francisco, USA and was runner-up in the Grand Challenge competition of ACM International Conference on Multimedia 2015, Brisbane, Austraila. He is involved in organizing and reviewing of many top-tier international conferences and journals. Recently, he has organized a workshop on Multimodal Representation, Retrieval, and Analysis of Multimedia Content (MR2AMC) in the conjunction of the first IEEE MIPR 2018 conference. His research interests include multimedia content processing, natural language processing, image processing, multimodal computing, data science, social media computing, and the internet of things.&lt;/p&gt;

&lt;p&gt;Specifically, his current research interests include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Multimodal deep learning based healthcare solutions&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multimodal fake news detection using deep learning techniques&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multimodal semantic and sentiment analysis of user-generated social media content&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Event detection and recommendation on social media&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Multimodal multimedia search, retrieval, and recommendation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep learning based multimedia systems&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Rajat</title>
   <link href="https://midas.iiitd.edu.in/team/rajat.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/rajat</id>
   <content type="html">&lt;p&gt;Hi, I am a Fourth-year student of Bachelor of Technology (B.Tech.) in Information Technology (IT) at Maharaja Agrasen Institute of Technology. I’m a resourceful, self motivated, machine learning enthusiast and talented software developer with extensive experience in Data science,Deep Learning,Text processing, ML models and Computer Vision. I am quick learner with the ability to multi-task. Thrives in environment that constantly embrace new technologies. I enjoy motivating and being part of a productive team, equally comfortable with working on own initiative. I believe in one thing that you can learn anything if you are dedicated enough towards it.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pratham Nawal</title>
   <link href="https://midas.iiitd.edu.in/team/pratham.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/pratham</id>
   <content type="html">&lt;p&gt;I’m a pre-final year student at NSIT. I’m passionate about social network analysis and data science for social good.Being a avid reader,  I like to read fiction, biographies and motivational novels.   I am always open for a talk and travel. I’m also invested in learning about natural language processing and generative adversarial networks.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Ponnurangam Kumaraguru</title>
   <link href="https://midas.iiitd.edu.in/team/pk.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/pk</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Dr. Omprakash Kaiwartya</title>
   <link href="https://midas.iiitd.edu.in/team/ompraksh.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/ompraksh</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Dr. Mukesh Prasad</title>
   <link href="https://midas.iiitd.edu.in/team/mukesh.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/mukesh</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Meghna P Ayyar</title>
   <link href="https://midas.iiitd.edu.in/team/meghna.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/meghna</id>
   <content type="html">&lt;p&gt;Research Student&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mayank Aggarwal</title>
   <link href="https://midas.iiitd.edu.in/team/mayank.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/mayank</id>
   <content type="html">&lt;p&gt;Mayank is an Undergraduate Student at NSIT. He loves to code &amp;amp; use Machine Learning &amp;amp; Deep learning model to create things having Real life Impact. He has Previously researched at NSIT &amp;amp; IIIT-D.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Laiba Mehnaz</title>
   <link href="https://midas.iiitd.edu.in/team/laiba.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/laiba</id>
   <content type="html">&lt;p&gt;I am a third year software engineering B.Tech student studying in Delhi Technological University. I am a data science enthusiast . I’m constantly looking for resources and ways to learn and become better at it. I am currently interning in IIITD where I am working on a medical dataset and I am using natural language processing for information extraction.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Jing Jiang</title>
   <link href="https://midas.iiitd.edu.in/team/jing.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/jing</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Hitkul</title>
   <link href="https://midas.iiitd.edu.in/team/hitkul.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/hitkul</id>
   <content type="html">&lt;p&gt;I am a PhD Research Scholar of Computer Science Department at Indraprastha Institute of Information Technology, Delhi under the guidance of Prof. Rajiv Ratn Shah and Prof. PK. I hold a B.Tech (2018) in Computer Science from BML Munjal University, Gurgaon. My research interest lies in solving social issues using data science and user generated content. Other than work I enjoy Powerlifting, Riding and Movies.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hitesh Nankani</title>
   <link href="https://midas.iiitd.edu.in/team/hitesh.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/hitesh</id>
   <content type="html">&lt;p&gt;I am a tech enthusiast, have a craze for trying out new things and solving challenging problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Himanshu</title>
   <link href="https://midas.iiitd.edu.in/team/himanshu.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/himanshu</id>
   <content type="html">&lt;p&gt;My name is Himanshu. Mathematics and Computing 3rd yr DTU(DCE). I am a python programmer and interested in NLP and computer vision problems. Currently I am working on machine translation.I am a huge cricket fan and love travelling and  PC gaming.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Debanjan Mahata</title>
   <link href="https://midas.iiitd.edu.in/team/debanjan.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/debanjan</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Ayush Gupta</title>
   <link href="https://midas.iiitd.edu.in/team/ayush.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/ayush</id>
   <content type="html">&lt;p&gt;I am a third year student at DTU interested in pursuing research in Data Science.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. A.V. Subramanyam</title>
   <link href="https://midas.iiitd.edu.in/team/avs.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/avs</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Akash Kumar</title>
   <link href="https://midas.iiitd.edu.in/team/akash.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/akash</id>
   <content type="html">&lt;p&gt;I am a senior year undergraduate student from Delhi Technological University majoring in Electronics &amp;amp; Communications. My primary research interests lies in the Deep Learning in Computer Vision Applications &amp;amp; Natural Language Processing. I am currently working on Content-based Video Relevance System.
I am interested to work on Single Shot Image Captioning, Visual Question Answering and Video Object Segmentation.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Agniv Sharma</title>
   <link href="https://midas.iiitd.edu.in/team/agniv.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/agniv</id>
   <content type="html">&lt;p&gt;I have successfully completed my B. Tech from Delhi Technological University and will be joining Western Digital as full-time employee . I am a mathematics, statistics and machine learning enthusiast, who also likes reading, playing instruments  and learning new things in my free time&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Abhigyan Khaund</title>
   <link href="https://midas.iiitd.edu.in/team/abhigyan.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/abhigyan</id>
   <content type="html">&lt;p&gt;I am Abhigyan and a 2nd year student at IIT Mandi. I am interested in Deep Learning problems and also explore the field of Reinforcement learning.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Aarya Patel</title>
   <link href="https://midas.iiitd.edu.in/team/aarya.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/aarya</id>
   <content type="html">&lt;p&gt;I’m a third year undergraduate student at Jaypee Institute of Information Technology,Noida.I have undertaken Computer Science Engineering.
My objective is to pursue graduate studies in computer science and engineering, leading to a career in research.I’m interested in Computer Vision and Deep Learning. I have completed the Deep Learning Specialization on Cousera.
I am very enthusiastic about Deep Learning because it  gives us chance to learn about our own brain.This topic is very fresh in the computer Science field. So, it gives us an opportunity to contribute in this New world.I chose artificial intelligence because AI technology  will becomes the part of everyone’s life. From small to big work everyone will be using AI to generate leads and remove the work pressure. These technologies are so advanced that you don’t have to write code for every activity. They understand the motion of work automatically.Most companies are already leveraging AI in their applications such as self driving cars,UAVs , medical science , banks and financial systems and many more.It will be the a potential game changer that will revolutionise our lives.But it is our duty to keep AI in face hands ,so that it is not exploited by bad organisations.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Dr. Soujanya Poria</title>
   <link href="https://midas.iiitd.edu.in/team/Soujanya.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Soujanya</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Osaid Rehman Nasir</title>
   <link href="https://midas.iiitd.edu.in/team/Osaid.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/team/Osaid</id>
   <content type="html">&lt;p&gt;I am Osaid, CS and Applied Math undergrad student at IIIT Delhi. I am interested in Deep Learning, the theory behind it and it’s applications to NLP and CV. I love solving problems and working out.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MIDAS Lab is here</title>
   <link href="https://midas.iiitd.edu.in/news/midas_formed.html"/>
   <updated>2018-01-01T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/news/midas_formed</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://www.iiitd.ac.in/rajivratn&quot;&gt;Prof Rajiv Ratn Shah&lt;/a&gt; founded the MIDAS lab.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>FastShrinkage: Perceptually-aware Retargeting Toward Mobile Platforms</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/FastShrinkage.html"/>
   <updated>2017-10-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/FastShrinkage</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Retargeting aims at adapting an original high-resolution photo/video to a low-resolution screen with an arbitrary aspect ratio. Conventional approaches are generally based on desktop PCs, since the computation might be intolerable for mobile platforms (especially when retargeting videos). Besides, only low-level visual features are exploited typically, whereas human visual perception is not well encoded. In this paper, we propose a novel retargeting framework which fast shrinks photo/video by leveraging human gaze behavior. Specifically, we first derive a geometry-preserved graph ranking algorithm, which efficiently selects a few salient object patches to mimic human gaze shifting path (GSP) when viewing each scenery. Afterward, an aggregation-based CNN is developed to hierarchically learn the deep representation for each GSP. Based on this, a probabilistic model is developed to learn the priors of the training photos which are marked as aesthetically-pleasing by professional photographers. We utilize the learned priors to efficiently shrink the corresponding GSP of a retargeted photo/video to be maximally similar to those from the training photos. Extensive experiments have demonstrated that: 1) our method consumes less than 35ms to retarget a 1024 × 768 photo (or a 1280 × 720 video frame) on popular iOS/Android devices, which is orders of magnitude faster than the conventional retargeting algorithms; 2) the retargeted photos/videos produced by our method outperform its competitors significantly based on the paired-comparison-based user study; and 3) the learned GSPs are highly indicative of human visual attention according to the human eye tracking experiments.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Virtualization in Wireless Sensor Networks: Fault Tolerant Embedding for Internet of Things</title>
   <link href="https://midas.iiitd.edu.in/papers/paper/Virtualization-in-Wireless-Sensor-Networks.html"/>
   <updated>2017-06-20T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/papers/paper/Virtualization-in-Wireless-Sensor-Networks</id>
   <content type="html">
&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;Recently, virtualization in wireless sensor networks (WSNs) has witnessed significant attention due to the growing service domain for Internet of Things (IoT). Related literature on virtualization in WSNs explored resource optimization without considering communication failure in WSNs environments. The failure of a communication link in WSNs impacts many virtual networks running IoT services. In this context, this paper proposes a framework for optimizing fault tolerance (FT) in virtualization in WSNs, focusing on heterogeneous networks for service-oriented IoT applications. An optimization problem is formulated considering FT and communication delay as two conflicting objectives. An adapted nondominated sorting-based genetic algorithm (A-NSGA) is developed to solve the optimization problem. The major components of A-NSGA include chromosome representation, FT and delay computation, crossover and mutation, and nondominance-based sorting. Analytical and simulation-based comparative performance evaluation has been carried out. From the analysis of results, it is evident that the framework effectively optimizes FT for virtualization in WSNs.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Disaggregation assay data visualization</title>
   <link href="https://midas.iiitd.edu.in/data/postheat-disaggregation-yeast-visualization.html"/>
   <updated>2015-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/data/postheat-disaggregation-yeast-visualization</id>
   <content type="html">&lt;p&gt;Interactive data visualization for disaggregation and new-synthesis data from &lt;a href=&quot;/papers/paper/endogenous-aggregates&quot;&gt;our 2015 paper on heat-triggered protein aggregation in yeast&lt;/a&gt;, Figure 6. (Aggregation data visualization is &lt;a href=&quot;/data/heat-aggregation-yeast-visualization&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;Choose detected proteins by official yeast name, from &lt;a href=&quot;http://www.yeastgenome.org/&quot;&gt;SGD&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cells were grown at 30°C, shifted to labeled media, heat-shocked for 10 minutes at 42°C, moved back to 30°C for recovery, and protein in 100,000g supernatant measured. Y-axis is ratio of protein in supernatant between treated and control cells, X-axis is either time or temperature of shock. Linetype reflects isotopic label on the amino acids: solid line is arginine/lysine imported before onset of heat shock, dashed line is imported after shock.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;720&quot; src=&quot;https://dadrummond.shinyapps.io/ratiosup_shiny/&quot; frameborder=&quot;0&quot;&gt; &lt;/iframe&gt;

</content>
 </entry>
 
 <entry>
   <title>Aggregation assay data visualization</title>
   <link href="https://midas.iiitd.edu.in/data/heat-aggregation-yeast-visualization.html"/>
   <updated>2015-07-23T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/data/heat-aggregation-yeast-visualization</id>
   <content type="html">&lt;p&gt;Interactive data visualization for data from &lt;a href=&quot;/papers/paper/endogenous-aggregates&quot;&gt;our 2015 paper on heat-triggered protein aggregation in yeast&lt;/a&gt;, Figure 1. (Disaggregation data visualization is &lt;a href=&quot;/data/postheat-disaggregation-yeast-visualization&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;Choose detected proteins by official yeast name, from &lt;a href=&quot;http://www.yeastgenome.org/&quot;&gt;SGD&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Y-axis is proportion of protein in 100,000g supernatant, X-axis is either time or temperature of shock.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;720&quot; src=&quot;https://dadrummond.shinyapps.io/psup_shiny/&quot; frameborder=&quot;0&quot;&gt; &lt;/iframe&gt;

</content>
 </entry>
 
 <entry>
   <title>MIDAS@IIITD</title>
   <link href="https://midas.iiitd.edu.in/misc/home/home.html"/>
   <updated>2015-04-22T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/misc/home/home</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;MIDAS&lt;/strong&gt; is a group of researchers at IIIT-Delhi who study, analyze, and build different multimedia systems for society leveraging multimodal information. MIDAS stands for &lt;strong&gt;Multimodal Digital Media Analysis Lab&lt;/strong&gt; and it is founded by Dr. Rajiv Ratn Shah. Dr. Shah is an assistant professor in the Department of Computer Science and Engineering (jointly appointed with the Department of Human-Centered Design) at IIIT-Delhi. Our work at MIDAS includes Machine Learning, Multimedia Content Processing, Natural Language Processing, Image Processing, Multimodal Computing, Data Science, and Social Media Computing towards AI for Social Good. We believe in multidisciplinary collaborative research and work closely with eminent researchers from the National University of Singapore (NUS), Georgia Institute of Technology, The University of Texas at Austin, National Institute of Informatics (NII), Bloomberg, SLTI, and others.&lt;/p&gt;

&lt;!-- **MIDAS** is a group of researchers at IIIT-Delhi who study, analyze, and build different multimedia systems for society leveraging multimodal information. MIDAS stands for **Multimodal Digital Media Analysis Lab** and it is founded by Dr. Rajiv Ratn Shah. Dr. Shah is assistant professor in the department of Computer Science and Engineering (jointly appointed with the department of Human Centered Design) at IIIT-Delhi. Our work at MIDAS includes Machine Learning, Multimedia Content Processing, Natural Language Processing, Image Processing, Multimodal Computing, Data Science, Social Media Computing, and the Internet of Things. We believe in multidisciplinary collabrative research and work closely with eminent researchers from National University of Singapore (NUS), National Institute of Informatics (NII), Nanyang Technological University (NTU), Bloomberg, Arkana Lab, etc. --&gt;

&lt;p&gt;&lt;!-- At **MIDAS (Multimodal Digital Media Analysis Lab)**, we study, analyze, and build multimedia systems for society leveraging multimodal information. Founded by Dr. Rajiv Ratn Shah, an assistant professor in the Department of Computer Science and Engineering (joint appointment with the Department of Human Centered Design) at IIIT-Delhi. Our work at MIDAS includes machine learning, multimedia content processing, natural language processing, image processing, multimodal computing, data science, social media computing, and the internet of things. We belive in collabrative research and work closely with researchers from National University of Singapore (NUS), National Institute of Informatics (NII), Nanyang Technological University (NTU), Bloomberg, Arkana Lab, etc. --&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>About</title>
   <link href="https://midas.iiitd.edu.in/misc/about.html"/>
   <updated>2015-04-18T00:00:00+05:30</updated>
   <id>https://midas.iiitd.edu.in/misc/about</id>
   <content type="html">
&lt;p&gt;&lt;a name=&quot;purpose&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;purpose&quot;&gt;Purpose&lt;/h1&gt;

&lt;p&gt;This is where you’ll find the most up-to-date information on who we are, what we’re working on, what we’ve done, and how we did it. And how you can, too!&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;contact&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;mailing-address&quot;&gt;Mailing Address&lt;/h1&gt;
&lt;p&gt;Office: A-415, Level 4, New Academic Building, IIIT-Delhi,&lt;br /&gt;
Okhla Industrial Estate Phase 3, Near Govindpuri Metro Station,&lt;br /&gt;
Delhi – 110020.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;On the &lt;a href=&quot;https://goo.gl/maps/YA9syNcLAtQ2&quot;&gt;map&lt;/a&gt;, our lab is on the 4th floor of bulding under the marker.&lt;/p&gt;

&lt;h1 id=&quot;phone&quot;&gt;Phone&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Lab: +91-11-26907495&lt;/li&gt;
  &lt;li&gt;Email: midas@iiitd.ac.in&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;social&quot;&gt;Social&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/midasIIITD&quot;&gt;Twiiter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/company/midasiiitd/&quot;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/midasIIITD/&quot;&gt;Facebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- 
# Joining
We look for motivated students and interns in our group who are interested to work in the following
areas:
- Deep learning based multimedia systems
- Deep learning based natural language processing
- Deep learning based image processing
- Deep learning based healthcare solutions
- Multimodal social media analysis using deep learning techniques
- Event detection and recommendation on social media
- Multimodal multimedia search, retrieval, and recommendation, etc.

Interested students can email their latest CV at &lt;a href=&quot;mailto:midas@iiitd.ac.in?subject=Application for |INSERT POSITION YOU WANT TO APPLY FOR HERE|&quot;&gt;midas@iiitd.ac.in&lt;/a&gt;, subject line of email should follow the following format: Application for PhD/intern/RA/BTP etc.

We are also open to industry collaboration to solve interesting research problems which can facilitate
society. If you are interested to collaborate with MIDAS then feel free to call us at +91-11-26907495 or
email us at midas@iiitd.ac.in --&gt;

&lt;p&gt;&lt;a name=&quot;design&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;design-and-implementation&quot;&gt;Design and Implementation&lt;/h1&gt;

&lt;p&gt;I was inspired by &lt;a href=&quot;http://bedford.io&quot;&gt;Trevor Bedford&lt;/a&gt;’s and &lt;a href=&quot;http://drummondlab.org&quot;&gt;Allan Drummond&lt;/a&gt;’s clean, elegant, and functional site. More than inspired–I’ve copied many aspects of his site, from visual design to conceptual organization to under-the-hood code, at Drummond’s (&lt;a href=&quot;http://drummondlab.org/about.html&quot;&gt;public&lt;/a&gt;) invitation. Rather than branching his code, I started from a different boilerplate, and adopted/adapted bits of his code during customization.&lt;/p&gt;

&lt;p&gt;Keeping with a major Jekyll Bootstrap idea, the site separates content and presentation. Presentation information is stored in a new theme, the &lt;code class=&quot;highlighter-rouge&quot;&gt;lab&lt;/code&gt; theme, which may be useful to other research groups setting up sites.&lt;/p&gt;

&lt;p&gt;By using &lt;a href=&quot;http://sass-lang.com/&quot;&gt;Sass&lt;/a&gt; for stylesheets, the site gets virtually all the advantages of using &lt;a href=&quot;http://lesscss.org/&quot;&gt;Less&lt;/a&gt;, while exploiting native Sass support in &lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt;. The site uses &lt;a href=&quot;http://www.google.com/fonts&quot;&gt;Google Fonts&lt;/a&gt; as well, primarily &lt;a href=&quot;https://www.google.com/fonts/specimen/Open+Sans&quot;&gt;Open Sans&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The site’s source code is freely available on &lt;a href=&quot;https://github.com/Hitkul/MIDAS-IIITD_website&quot;&gt;GitHub&lt;/a&gt;. All code is placed under the MIT license. You’re welcome to borrow / repurpose code to build your own site, and if you do, I’d appreciate attribution and a link back &lt;a href=&quot;https://midas.iiitd.edu.in/about.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 
</feed>
